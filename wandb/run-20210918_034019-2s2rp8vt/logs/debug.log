2021-09-18 03:40:19,823 INFO    MainThread:2214 [wandb_init.py:_log_setup():292] Logging user logs to wandb/run-20210918_034019-2s2rp8vt/logs/debug.log
2021-09-18 03:40:19,824 INFO    MainThread:2214 [wandb_init.py:_log_setup():293] Logging internal logs to wandb/run-20210918_034019-2s2rp8vt/logs/debug-internal.log
2021-09-18 03:40:19,824 INFO    MainThread:2214 [wandb_setup.py:_flush():69] setting env: {}
2021-09-18 03:40:19,825 INFO    MainThread:2214 [wandb_setup.py:_flush():69] setting user settings: {'email': 'saburotyan758@gmail.com'}
2021-09-18 03:40:19,825 INFO    MainThread:2214 [wandb_setup.py:_flush():69] multiprocessing start_methods=fork,spawn,forkserver
2021-09-18 03:40:19,825 INFO    MainThread:2214 [wandb_setup.py:_flush():69] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f6c9871b450>
2021-09-18 03:40:21,146 INFO    MainThread:2214 [wandb_run.py:_console_start():1276] atexit reg
2021-09-18 03:40:21,153 INFO    MainThread:2214 [wandb_run.py:_redirect():1146] redirect: SettingsConsole.WRAP
2021-09-18 03:40:21,154 INFO    MainThread:2214 [wandb_run.py:_redirect():1177] Wrapping output streams.
2021-09-18 03:40:21,155 INFO    MainThread:2214 [wandb_run.py:_redirect():1193] Redirects installed.
2021-09-18 03:40:21,159 INFO    MainThread:2214 [wandb_run.py:_config_callback():586] config_cb None None {'_wandb': {'cli_version': '0.10.7', 'python_version': '3.7.12', 'is_jupyter_run': True, 'is_kaggle_kernel': False, 'framework': 'torch'}, 'experiment/seed': 42, 'experiment/data': 'mhqg-wq', 'experiment/data_dir': 'data/mhqg-wq/', 'experiment/model_name_or_path': 't5-small', 'experiment/tokenizer_name_or_path': 't5-small', 'experiment/model_dir': 'content/test_mhqg-wq_t5-small_with_TripleAttention_20210918_1218', 'experiment/wandb/exp_num': 1, 'experiment/wandb/project': 'test_mhqg-wq_t5-small_with_TripleAttention', 'experiment/wandb/checkpoint_path': 'checkpoint/', 'model/max_input_length': 100, 'model/max_target_length': 100, 'training/learning_rate': 0.0003, 'training/weight_decay': 0.0, 'training/adam_epsilon': 1e-08, 'training/warmup_steps': 0, 'training/gradient_accumulation_steps': 1, 'training/early_stop_callback': True, 'training/fp_16': False, 'training/opt_level': 'O1', 'training/max_grad_norm': 1.0, 'training/seed': 42, 'training/train_batch_size': 32, 'training/eval_batch_size': 32, 'training/test_batch_size': 8, 'training/num_train_epochs': 10, 'training/precision': 16, 'training/n_gpu': 0}
2021-09-18 03:40:21,913 INFO    MainThread:2214 [wandb_init.py:_pause_backend():214] pausing backend
2021-09-18 03:40:33,910 INFO    MainThread:2214 [wandb_init.py:_resume_backend():219] resuming backend
2021-09-18 03:40:35,487 INFO    MainThread:2214 [wandb_init.py:_pause_backend():214] pausing backend
2021-09-18 03:40:57,149 INFO    MainThread:2214 [wandb_init.py:_resume_backend():219] resuming backend
2021-09-18 03:40:57,190 INFO    MainThread:2214 [wandb_run.py:_config_callback():586] config_cb None None {'_wandb': {'cli_version': '0.10.7', 'python_version': '3.7.12', 'is_jupyter_run': True, 'is_kaggle_kernel': False, 'framework': 'torch'}, 'experiment/seed': 42, 'experiment/data': 'mhqg-wq', 'experiment/data_dir': 'data/mhqg-wq/', 'experiment/model_name_or_path': 't5-small', 'experiment/tokenizer_name_or_path': 't5-small', 'experiment/model_dir': 'content/test_mhqg-wq_t5-small_with_TripleAttention_20210918_1218', 'experiment/wandb/exp_num': 1, 'experiment/wandb/project': 'test_mhqg-wq_t5-small_with_TripleAttention', 'experiment/wandb/checkpoint_path': 'checkpoint/', 'model/max_input_length': 100, 'model/max_target_length': 100, 'training/learning_rate': 0.0003, 'training/weight_decay': 0.0, 'training/adam_epsilon': 1e-08, 'training/warmup_steps': 0, 'training/gradient_accumulation_steps': 1, 'training/early_stop_callback': True, 'training/fp_16': False, 'training/opt_level': 'O1', 'training/max_grad_norm': 1.0, 'training/seed': 42, 'training/train_batch_size': 32, 'training/eval_batch_size': 32, 'training/test_batch_size': 8, 'training/num_train_epochs': 10, 'training/precision': 16, 'training/n_gpu': 0}
2021-09-18 03:40:57,702 INFO    MainThread:2214 [wandb_init.py:_pause_backend():214] pausing backend
2021-09-18 03:42:13,495 INFO    MainThread:2214 [wandb_init.py:_resume_backend():219] resuming backend
2021-09-18 03:42:15,190 INFO    MainThread:2214 [wandb_init.py:_pause_backend():214] pausing backend
2021-09-18 03:42:32,937 INFO    MainThread:2214 [wandb_init.py:_resume_backend():219] resuming backend
2021-09-18 03:42:32,974 INFO    MainThread:2214 [wandb_run.py:_config_callback():586] config_cb None None {'_wandb': {'cli_version': '0.10.7', 'python_version': '3.7.12', 'is_jupyter_run': True, 'is_kaggle_kernel': False, 'framework': 'torch'}, 'experiment/seed': 42, 'experiment/data': 'mhqg-wq', 'experiment/data_dir': 'data/mhqg-wq/', 'experiment/model_name_or_path': 't5-small', 'experiment/tokenizer_name_or_path': 't5-small', 'experiment/model_dir': 'content/test_mhqg-wq_t5-small_with_TripleAttention_20210918_1218', 'experiment/wandb/exp_num': 1, 'experiment/wandb/project': 'test_mhqg-wq_t5-small_with_TripleAttention', 'experiment/wandb/checkpoint_path': 'checkpoint/', 'model/max_input_length': 100, 'model/max_target_length': 100, 'training/learning_rate': 0.0003, 'training/weight_decay': 0.0, 'training/adam_epsilon': 1e-08, 'training/warmup_steps': 0, 'training/gradient_accumulation_steps': 1, 'training/early_stop_callback': True, 'training/fp_16': False, 'training/opt_level': 'O1', 'training/max_grad_norm': 1.0, 'training/seed': 42, 'training/train_batch_size': 32, 'training/eval_batch_size': 32, 'training/test_batch_size': 8, 'training/num_train_epochs': 10, 'training/precision': 16, 'training/n_gpu': 0}
2021-09-18 03:44:46,499 INFO    MainThread:2214 [wandb_watch.py:watch():32] Watching
2021-09-18 03:44:46,701 INFO    MainThread:2214 [wandb_init.py:_pause_backend():214] pausing backend
2021-09-18 03:45:51,120 INFO    MainThread:2214 [wandb_init.py:_resume_backend():219] resuming backend
2021-09-18 03:45:51,238 INFO    MainThread:2214 [wandb_init.py:_pause_backend():214] pausing backend
2021-09-18 03:45:56,446 INFO    MainThread:2214 [wandb_init.py:_resume_backend():219] resuming backend
2021-09-18 03:45:56,560 INFO    MainThread:2214 [wandb_init.py:_pause_backend():214] pausing backend
2021-09-18 03:46:01,454 INFO    MainThread:2214 [wandb_run.py:_atexit_cleanup():1249] got exitcode: 0
2021-09-18 03:46:01,455 INFO    MainThread:2214 [wandb_run.py:_restore():1221] restore
2021-09-18 03:46:01,470 INFO    MainThread:2214 [wandb_run.py:_wait_for_finish():1360] got exit ret: uuid: "2f8be1dee8ea429d8eb5c98e86cf5122"
response {
  poll_exit_response {
    file_counts {
      wandb_count: 1
    }
    pusher_stats {
      uploaded_bytes: 780
      total_bytes: 780
    }
  }
}

2021-09-18 03:46:03,495 INFO    MainThread:2214 [wandb_run.py:_wait_for_finish():1360] got exit ret: uuid: "2398971ae32c4a1186afb736280123e4"
response {
  poll_exit_response {
    done: true
    exit_result {
    }
    file_counts {
      wandb_count: 5
    }
    pusher_stats {
      uploaded_bytes: 10499
      total_bytes: 10499
    }
  }
}

2021-09-18 03:46:04,682 INFO    MainThread:2214 [wandb_run.py:_show_files():1554] logging synced files
2021-09-18 03:46:04,690 INFO    MainThread:2214 [internal.py:handle_exit():137] Internal process exited
