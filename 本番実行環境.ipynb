{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"本番実行環境.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1ZzUyjVoSjL3Xmcf02iAOnQL004cNiJkn","authorship_tag":"ABX9TyMfoCP2DALERke5bbgvCVpF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7da568f66ac147fba5e6f4cf5093d6d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b6f73c325b6948b787ec12ef1ce17ee1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7a2c83e16a834dc5ad808b3c853a5cde","IPY_MODEL_181e0e8023d84991b72011a8f32aaaa1","IPY_MODEL_010eaeeb143b4bb58ec0a5633399817c"]}},"b6f73c325b6948b787ec12ef1ce17ee1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"7a2c83e16a834dc5ad808b3c853a5cde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9ef67b35f3904947a0337d5b9a6cc716","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validation sanity check:   0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be1f025fe5f440aab90f6c6974d57f5f"}},"181e0e8023d84991b72011a8f32aaaa1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9cf4b6396f19417491bff8922ba15893","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f9597c01e40c47d78f8aedbb542fd257"}},"010eaeeb143b4bb58ec0a5633399817c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_533f1bfb9b204fa890c9eadc195f4ad1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/2 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9af6adb75cea42f18b3ae61a8347445b"}},"9ef67b35f3904947a0337d5b9a6cc716":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"be1f025fe5f440aab90f6c6974d57f5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9cf4b6396f19417491bff8922ba15893":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f9597c01e40c47d78f8aedbb542fd257":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"533f1bfb9b204fa890c9eadc195f4ad1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9af6adb75cea42f18b3ae61a8347445b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"385fc4f4a1684349b96be1f2a74cef24":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_537c04f5c2fe4b2b93c916e21dc3c967","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_461f893479044fc3a8220a032af10c35","IPY_MODEL_81fb7c6944de404aa37ae2db9395027b","IPY_MODEL_dd7955c48b9f4344867d58ab3dee2480"]}},"537c04f5c2fe4b2b93c916e21dc3c967":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"461f893479044fc3a8220a032af10c35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_86930b38a03f4a6a9eb66502cc9ba712","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 7: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_437061a9f4eb43a89c6d4b48a1e539d1"}},"81fb7c6944de404aa37ae2db9395027b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_31a312cba4704ee49af5b0993be52ed5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":10494,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10494,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_842819408b05413e9dc8d7247ab9890e"}},"dd7955c48b9f4344867d58ab3dee2480":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0f9d62c1ba574450a602a9f497c49e36","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10494/10494 [21:12&lt;00:00,  8.25it/s, loss=0.727, v_num=jt6z]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da40de994f054d5bb43d4e0ffdde3f82"}},"86930b38a03f4a6a9eb66502cc9ba712":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"437061a9f4eb43a89c6d4b48a1e539d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31a312cba4704ee49af5b0993be52ed5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"842819408b05413e9dc8d7247ab9890e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f9d62c1ba574450a602a9f497c49e36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"da40de994f054d5bb43d4e0ffdde3f82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a8083708fe124deebde2df1f940cecab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4c5fe4f26fec4d37bd7aed84d2da1d85","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d898bfe0cfb6451b92d8c4bdb2088ed6","IPY_MODEL_ee18d4e3df2c44fb8242af3a3296dff2","IPY_MODEL_7b31055307b84f63964409a5be93c319"]}},"4c5fe4f26fec4d37bd7aed84d2da1d85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"d898bfe0cfb6451b92d8c4bdb2088ed6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3a4e37aab7934140bf026c843ce3ab2d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_671ccf76da3d4627a8b40a469584a557"}},"ee18d4e3df2c44fb8242af3a3296dff2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_510f25f2d0eb45ee9e743606da9bf8ca","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_42732c62e8d9483685cbd3c183fc4317"}},"7b31055307b84f63964409a5be93c319":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d48a65b64bca48b7b1599386b60643c5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:58&lt;00:00, 17.80it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7aa9846c9248414fa0a5dcabc29a2fd1"}},"3a4e37aab7934140bf026c843ce3ab2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"671ccf76da3d4627a8b40a469584a557":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"510f25f2d0eb45ee9e743606da9bf8ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"42732c62e8d9483685cbd3c183fc4317":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d48a65b64bca48b7b1599386b60643c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7aa9846c9248414fa0a5dcabc29a2fd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a8d539825f6849b19e013dabd894a101":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bf7e08793dc14986b3d039f0affd087b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0c730750e42c4f8db300d1dc8243e1d4","IPY_MODEL_30bc510fc75c4eb4af7214e9309434ac","IPY_MODEL_92f6e3f59a6f45d9b238e38b0a57626d"]}},"bf7e08793dc14986b3d039f0affd087b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"0c730750e42c4f8db300d1dc8243e1d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3bae42da7e0344babbdbc9f3893e1cef","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3061013f00094c8d9dd677b1cdf4c0ad"}},"30bc510fc75c4eb4af7214e9309434ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2f8dbe3916074bf2a2e8c1b2037d2862","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_35447a73c31e4b23ae13c11adf49b320"}},"92f6e3f59a6f45d9b238e38b0a57626d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_304fb778ddbc4c979209ad553473ea4d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:58&lt;00:00, 17.49it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aefb805e2b5942d0bbb87fab715e053d"}},"3bae42da7e0344babbdbc9f3893e1cef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3061013f00094c8d9dd677b1cdf4c0ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f8dbe3916074bf2a2e8c1b2037d2862":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"35447a73c31e4b23ae13c11adf49b320":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"304fb778ddbc4c979209ad553473ea4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aefb805e2b5942d0bbb87fab715e053d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9682ed40595b49608658d5d837a9b9e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b9cad575fc844a999e677096cee866f6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_34401605a168419f88d73569fbf207cf","IPY_MODEL_3d91898bed69489ea8adaa7ed317e66a","IPY_MODEL_cc98e3eb1d1848f196e85ceaf34226fb"]}},"b9cad575fc844a999e677096cee866f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"34401605a168419f88d73569fbf207cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6cd407e1aa154ed099886bd6241e1954","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_48b50abb73594bf7818f8dfc3aa552c6"}},"3d91898bed69489ea8adaa7ed317e66a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a93f2c14d6a34bfb97a6fb23d5e291a7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5f8b3f23d35f4061af33f308d3457ae9"}},"cc98e3eb1d1848f196e85ceaf34226fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fff3596d608348d5950e700daede7584","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:58&lt;00:00, 17.37it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8b20f2595764ea7ad2704d34200f40b"}},"6cd407e1aa154ed099886bd6241e1954":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"48b50abb73594bf7818f8dfc3aa552c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a93f2c14d6a34bfb97a6fb23d5e291a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5f8b3f23d35f4061af33f308d3457ae9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fff3596d608348d5950e700daede7584":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c8b20f2595764ea7ad2704d34200f40b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c7530fd401a4e32987a7971070a9e4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6797928bf035463fb6b7882a028ab13f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e150142c6d9f4a11b373972c7e56cbf5","IPY_MODEL_c28f55577d024a52a36c61433074db24","IPY_MODEL_1af7ce775ba440338f670d937c5edbfb"]}},"6797928bf035463fb6b7882a028ab13f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"e150142c6d9f4a11b373972c7e56cbf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3cfa97059b8a462881e5d4b79ea9919f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c6037db488094b6c85c7dfac8bd53f02"}},"c28f55577d024a52a36c61433074db24":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4e0e5826c561480798448848b3b74394","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9352deb504484ee5962ccf654f0baf7d"}},"1af7ce775ba440338f670d937c5edbfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8fd42dbbcfc248ec9a2b2e169ab3a45f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:58&lt;00:00, 17.23it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9540c8e533d44a05adcba875c72d3177"}},"3cfa97059b8a462881e5d4b79ea9919f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c6037db488094b6c85c7dfac8bd53f02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4e0e5826c561480798448848b3b74394":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9352deb504484ee5962ccf654f0baf7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8fd42dbbcfc248ec9a2b2e169ab3a45f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9540c8e533d44a05adcba875c72d3177":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75fecdcc1276491ea1b25d9df20a0974":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_884a0cfd41904c7a8de19b1b0387c348","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b2795dae575c4609b3a649fd659eaa55","IPY_MODEL_69485019139f42a8a061f9c1a7e20b80","IPY_MODEL_b1a66305f2b34fb6a0e4ce1c9ac711bc"]}},"884a0cfd41904c7a8de19b1b0387c348":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"b2795dae575c4609b3a649fd659eaa55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bfffe8148f0142e58fce9acd7195ba52","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a6e54c25a7004a4e83804968b62dc1b6"}},"69485019139f42a8a061f9c1a7e20b80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9b3be0b2151242d4b5d707d4d109839a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_406a10f47ef44a60bdbd510e556866fa"}},"b1a66305f2b34fb6a0e4ce1c9ac711bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_266a8114d22c4857bd48e03904f87892","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:58&lt;00:00, 17.53it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a8d790bd486546f5989a6154f21cd2d9"}},"bfffe8148f0142e58fce9acd7195ba52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a6e54c25a7004a4e83804968b62dc1b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b3be0b2151242d4b5d707d4d109839a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"406a10f47ef44a60bdbd510e556866fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"266a8114d22c4857bd48e03904f87892":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a8d790bd486546f5989a6154f21cd2d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"afb6f64cb7744145bdfac4c470f21df9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4b964b0e8cce4a54979fb03c1896c69b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_146abf6aaca8471e85cc467f1dd6510b","IPY_MODEL_5a71e9e909704657abc696880011e133","IPY_MODEL_b85cb10f89be48e898a9576886d94dc0"]}},"4b964b0e8cce4a54979fb03c1896c69b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"146abf6aaca8471e85cc467f1dd6510b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3afc1aaaa0f04f3baf7de43fb273e72f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b22600cfaad84991a29ca880a9518ee9"}},"5a71e9e909704657abc696880011e133":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3dbdace2cab9442789c69113d74afe81","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9ed1a39735e14fb0a61a2ac0876a64d8"}},"b85cb10f89be48e898a9576886d94dc0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_83411bc3ece34b73b6b6471ba79ab294","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:58&lt;00:00, 17.41it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_301804d21e824ce3b732ee7de203d820"}},"3afc1aaaa0f04f3baf7de43fb273e72f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b22600cfaad84991a29ca880a9518ee9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3dbdace2cab9442789c69113d74afe81":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9ed1a39735e14fb0a61a2ac0876a64d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83411bc3ece34b73b6b6471ba79ab294":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"301804d21e824ce3b732ee7de203d820":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71f0a60bd9484a5f9aced7298e21eabd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ae88247f0b1a491e8edae040abee2536","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8b3f86ac047d4fafbf84e569bd08ea0a","IPY_MODEL_b0ee9d850d554c1e84158ffe8d46f46b","IPY_MODEL_63f062ff8de84c43a1ae03b95921541d"]}},"ae88247f0b1a491e8edae040abee2536":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"8b3f86ac047d4fafbf84e569bd08ea0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_730ed3e563e543ee8fc189fa28bc0a1d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2853e46926a7498ead12f4626b3e06e5"}},"b0ee9d850d554c1e84158ffe8d46f46b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6380c96af0644de5ba338e47935deb48","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_32ab4949d1cc463193256abe34c71fcd"}},"63f062ff8de84c43a1ae03b95921541d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d1472da01fd34ccab511d4301d11d2ed","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:58&lt;00:00, 17.43it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7baecf40614040148ea25117732d6160"}},"730ed3e563e543ee8fc189fa28bc0a1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2853e46926a7498ead12f4626b3e06e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6380c96af0644de5ba338e47935deb48":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"32ab4949d1cc463193256abe34c71fcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1472da01fd34ccab511d4301d11d2ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7baecf40614040148ea25117732d6160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14e18ba82a05401dbeb1b07ac8b4aa5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6ae54f5fe3c54afbb24b5b3b2498c35e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2e941c632e1d43099340e2b009734e39","IPY_MODEL_a19320b55100482497e45072a9c3ec85","IPY_MODEL_b42882d6acbd47848ebcaf0c48a0c197"]}},"6ae54f5fe3c54afbb24b5b3b2498c35e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"2e941c632e1d43099340e2b009734e39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e0b7f940001e473e984dbc5c7f192892","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d27f753173c4965ac1ecc6488d4fb35"}},"a19320b55100482497e45072a9c3ec85":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0e9ddf78e60b4babb080bc34ef00ad01","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_80d028505ccc49979428d841f2bb2eff"}},"b42882d6acbd47848ebcaf0c48a0c197":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8f94d408eee44aee8faff95e12e5f931","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1000/1000 [00:58&lt;00:00, 17.64it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c662fc1c5b6a4ad5985886a4905f1dc7"}},"e0b7f940001e473e984dbc5c7f192892":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3d27f753173c4965ac1ecc6488d4fb35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e9ddf78e60b4babb080bc34ef00ad01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"80d028505ccc49979428d841f2bb2eff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8f94d408eee44aee8faff95e12e5f931":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c662fc1c5b6a4ad5985886a4905f1dc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ba3bee47cc84926846d3495abfb627d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6de5c51ba0c24ab891c3f95f8b671ba3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a9b4cd516d594e5db1a49a2e92b492da","IPY_MODEL_6bc777c2e5a54c0e9eab31bc0408b73c","IPY_MODEL_25321cff582a479ca9ab46e48d7e4061"]}},"6de5c51ba0c24ab891c3f95f8b671ba3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"a9b4cd516d594e5db1a49a2e92b492da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_63b5eaec9812496189f59940029e9610","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Testing: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e172f12440734314accad4c23828dd23"}},"6bc777c2e5a54c0e9eab31bc0408b73c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_73a02320509c482ba56f91740306645b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d12153d1a3d44e4f95bc5b919671ccc0"}},"25321cff582a479ca9ab46e48d7e4061":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_32cbb6533aa24597b261cdc52bdd3e73","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 250/250 [03:57&lt;00:00,  1.09it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_543fcba76e4b4b88b8a89726eef666e6"}},"63b5eaec9812496189f59940029e9610":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e172f12440734314accad4c23828dd23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73a02320509c482ba56f91740306645b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d12153d1a3d44e4f95bc5b919671ccc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32cbb6533aa24597b261cdc52bdd3e73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"543fcba76e4b4b88b8a89726eef666e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b3febc27bfba418b8ae11dec7592c163":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7391128ca9dd4507a907416d2792e46e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e2e02dd621ec41fe838a111d16d77abe","IPY_MODEL_6f0ddaec947745098c7b80b7209d6d4c"]}},"7391128ca9dd4507a907416d2792e46e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e2e02dd621ec41fe838a111d16d77abe":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_443da9428e1d49ee97d03651cc65b1e9","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 692.88MB of 692.88MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b872775199e049a39909cd24cec0b0ba"}},"6f0ddaec947745098c7b80b7209d6d4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8107f05863f34b9f89e0151041a7e351","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29d8bc2f0f354913a91efac9c79b581d"}},"443da9428e1d49ee97d03651cc65b1e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b872775199e049a39909cd24cec0b0ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8107f05863f34b9f89e0151041a7e351":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"29d8bc2f0f354913a91efac9c79b581d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"711ae15ff82f40e0883ff00c3197c6e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_398edfab12a346259628b7e6e94608b5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1f0a21ba51af452ca84c23f9d969b6a2","IPY_MODEL_b088865bb0bc4cb687ae9efca96b7d39","IPY_MODEL_12c2010d488249509f12d2924ad76180"]}},"398edfab12a346259628b7e6e94608b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f0a21ba51af452ca84c23f9d969b6a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7addbe405f2644d2b601d5033681f276","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d7a474333b144fab90445a1ed9567613"}},"b088865bb0bc4cb687ae9efca96b7d39":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_78ed48e18f9b4633956ebb980f8b4a07","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1197,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1197,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_56e2d2362cf042ae9df3c59af3b21b6b"}},"12c2010d488249509f12d2924ad76180":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a950d5bfa7cc408fa9e75d7a5ddca675","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.20k/1.20k [00:00&lt;00:00, 45.9kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a8f0f87abccc4966a0278dc4100d99d2"}},"7addbe405f2644d2b601d5033681f276":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d7a474333b144fab90445a1ed9567613":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78ed48e18f9b4633956ebb980f8b4a07":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"56e2d2362cf042ae9df3c59af3b21b6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a950d5bfa7cc408fa9e75d7a5ddca675":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a8f0f87abccc4966a0278dc4100d99d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9719c5e1676b464887154bbf0dcf6087":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_28f4ef79fa554a298ba74ba79597f417","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f0c5e178e48f4b358414e9b3581c0205","IPY_MODEL_a638138187ef47c7837807bb639ecc38","IPY_MODEL_8a3442239c444bb58f96054f0682088c"]}},"28f4ef79fa554a298ba74ba79597f417":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0c5e178e48f4b358414e9b3581c0205":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_39e943a38a154caa8a6038929cd6f5cd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1158150af5094e52917605d3028cf1e4"}},"a638138187ef47c7837807bb639ecc38":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_24c625354c4742609e4b4709a058efd0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":242065649,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":242065649,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7067f7629e34e4ea5134f10b701c3c6"}},"8a3442239c444bb58f96054f0682088c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1797e7efe60047f3adf71b7536ea242c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 242M/242M [00:04&lt;00:00, 52.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f2bf94211b0c4e4bbcd4dc977f97a6b1"}},"39e943a38a154caa8a6038929cd6f5cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1158150af5094e52917605d3028cf1e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"24c625354c4742609e4b4709a058efd0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a7067f7629e34e4ea5134f10b701c3c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1797e7efe60047f3adf71b7536ea242c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f2bf94211b0c4e4bbcd4dc977f97a6b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99e5be9462f648189e100a383203be9c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4a1ca5e0c618452fad60c0f8fc4e7829","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f3488b95a1aa4d3ea712e89b93b3c42b","IPY_MODEL_87019f8d0f794a4497d06c9211aff2c5","IPY_MODEL_fb4d876be6b94593b7bcc3221e5347ae"]}},"4a1ca5e0c618452fad60c0f8fc4e7829":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3488b95a1aa4d3ea712e89b93b3c42b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d4bff213d84a42de81aa4c474ae468b5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5b9f85b7feaa4f3c81a90f32dfa9ecc5"}},"87019f8d0f794a4497d06c9211aff2c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_050dcc8007664fb4a740001bc1267497","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":791656,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":791656,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c9334d6e7134c2a8a6409915722d721"}},"fb4d876be6b94593b7bcc3221e5347ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_00ed0aba038e431b8856d99dc53d2b92","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 792k/792k [00:00&lt;00:00, 1.37MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f19aba35e9740f2ad963e257605a000"}},"d4bff213d84a42de81aa4c474ae468b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5b9f85b7feaa4f3c81a90f32dfa9ecc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"050dcc8007664fb4a740001bc1267497":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3c9334d6e7134c2a8a6409915722d721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00ed0aba038e431b8856d99dc53d2b92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8f19aba35e9740f2ad963e257605a000":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"890d00d7f0d64e64a7311d8479ab2e6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b4b62762f3bb4deaa451919ce59601ca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e0ae50450a7d4a7492d357175001bf5e","IPY_MODEL_bd83e1cf6d2846b6b931c3d9f0265fb4","IPY_MODEL_565687a7c2174b308e68622402f354cb"]}},"b4b62762f3bb4deaa451919ce59601ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0ae50450a7d4a7492d357175001bf5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b975cb927f234152830b8e6f47169409","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f6c6636f547437ea1f18bd5f8341367"}},"bd83e1cf6d2846b6b931c3d9f0265fb4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_713f59582e39422cb50484ccbd99e81a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1389353,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1389353,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f321eb16048343cd89edd73f790dfa66"}},"565687a7c2174b308e68622402f354cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9cf6b47722bd455c802680cdeef4e839","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.39M/1.39M [00:00&lt;00:00, 4.22MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a53775c819de4b349c7922ac930f212c"}},"b975cb927f234152830b8e6f47169409":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0f6c6636f547437ea1f18bd5f8341367":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"713f59582e39422cb50484ccbd99e81a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f321eb16048343cd89edd73f790dfa66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9cf6b47722bd455c802680cdeef4e839":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a53775c819de4b349c7922ac930f212c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e5a2fa97ced47dca7634e574cfe6901":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3054a7198483406cb10abd47be65b91a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6a33090a9bc44c379f5d1894061a4191","IPY_MODEL_4679428018454b1eb4b4e1cecae74c42","IPY_MODEL_5bf372526ebb4954a67fd0a3e30148c5"]}},"3054a7198483406cb10abd47be65b91a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"6a33090a9bc44c379f5d1894061a4191":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_46bdfb6fc47b405282972650dd86df65","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validation sanity check:   0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_208b5559419b40de8276ad71192de381"}},"4679428018454b1eb4b4e1cecae74c42":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8d5e9291618740c1929c203eb1d4eb45","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c3855c46d7294dda8335b4f503882ea1"}},"5bf372526ebb4954a67fd0a3e30148c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3e51b722d3224de58607cd818217369c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/2 [00:02&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0c11fc7a1deb4bbf8be5cb960fe96166"}},"46bdfb6fc47b405282972650dd86df65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"208b5559419b40de8276ad71192de381":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d5e9291618740c1929c203eb1d4eb45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c3855c46d7294dda8335b4f503882ea1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e51b722d3224de58607cd818217369c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0c11fc7a1deb4bbf8be5cb960fe96166":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2fb71916ecf943a3b284e2c7a8e6c73a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c74cc44ab9c446a7a2797bd4021efb60","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e181b9894b424bfe955b74a90b19c309","IPY_MODEL_9211c00821964d29803fcb9b7b1229bc","IPY_MODEL_9d045e2eb13046a0a22e507356a1ae6b"]}},"c74cc44ab9c446a7a2797bd4021efb60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"e181b9894b424bfe955b74a90b19c309":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_36f3dd041fc748de87378a6567a1c793","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 7: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_17017989e28b442c922b719082a5401f"}},"9211c00821964d29803fcb9b7b1229bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f0581ea1d4da491d9bda8164b3bf915e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":5396,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5396,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef552172a2a54bd2829f5b3fa2f727a4"}},"9d045e2eb13046a0a22e507356a1ae6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0beb7b2d6ad34c12bacecf992e77729b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5396/5396 [09:07&lt;00:00,  9.86it/s, loss=0.233, v_num=oso0]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_93c850d51a3d400888168ff34832f57c"}},"36f3dd041fc748de87378a6567a1c793":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"17017989e28b442c922b719082a5401f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0581ea1d4da491d9bda8164b3bf915e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ef552172a2a54bd2829f5b3fa2f727a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0beb7b2d6ad34c12bacecf992e77729b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"93c850d51a3d400888168ff34832f57c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f63281b1a79f4d8aaa3893ef4d58eedc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_55ab68efcf164a52abfcb44cbd44c512","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d9d5247995eb41a89cdddde1d21c584e","IPY_MODEL_6dfe2d66383d4936987ddfc4b8e078f7","IPY_MODEL_b03bbef45f3c46ce859c8e2f127fa589"]}},"55ab68efcf164a52abfcb44cbd44c512":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"d9d5247995eb41a89cdddde1d21c584e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a05a20c996794d74a1857c41080a2e34","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c479cb8affd441cc89b8a7daec159692"}},"6dfe2d66383d4936987ddfc4b8e078f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_19ff72e88ba64f29aea16ab4cd1fcb0c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c20c246502444c2bfffbba4987f4afd"}},"b03bbef45f3c46ce859c8e2f127fa589":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bc05816ea91f49a380398c1a9e033d3d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500/500 [00:22&lt;00:00, 26.69it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4826a195aedc42528c6f47fcd7abed2b"}},"a05a20c996794d74a1857c41080a2e34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c479cb8affd441cc89b8a7daec159692":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19ff72e88ba64f29aea16ab4cd1fcb0c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6c20c246502444c2bfffbba4987f4afd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc05816ea91f49a380398c1a9e033d3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4826a195aedc42528c6f47fcd7abed2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"204f7bd706f5481f95cc0504eef5bdeb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5aeea703d4a145ba8585a57b822c8636","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cbd0582213574704880f48d36e1d3e64","IPY_MODEL_3d9d16c145304c0ab4830e61cce2ead7","IPY_MODEL_ac666bc61f4d4056bd293a43a9cda1e9"]}},"5aeea703d4a145ba8585a57b822c8636":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"cbd0582213574704880f48d36e1d3e64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fd421455422742b3a69654c27a9a6d4a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0759f0eb9c34631a53bf8432e24364d"}},"3d9d16c145304c0ab4830e61cce2ead7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c737227a0e3e4c22ac79d1d16db96be4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f9b0f4f4297d45efa2f21f9632afbbd2"}},"ac666bc61f4d4056bd293a43a9cda1e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_33a08564ee0d4fbc8164fe2cb0296f0d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500/500 [00:29&lt;00:00, 17.53it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b1296e0834c440898fdac5319f251161"}},"fd421455422742b3a69654c27a9a6d4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d0759f0eb9c34631a53bf8432e24364d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c737227a0e3e4c22ac79d1d16db96be4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f9b0f4f4297d45efa2f21f9632afbbd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33a08564ee0d4fbc8164fe2cb0296f0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b1296e0834c440898fdac5319f251161":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"294c8a51559246059ea5853189aa7ab1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0c9ffccae9e34a5a84da0c73f4882784","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5bcec0373de84e7a84d3219504a0d720","IPY_MODEL_c8435f25b9ca45c8a919bcb137b69381","IPY_MODEL_bb80ead12dd445c4a0728c4a4107b39f"]}},"0c9ffccae9e34a5a84da0c73f4882784":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"5bcec0373de84e7a84d3219504a0d720":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7cb5babce74e44bd86a2736c41803f8b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_692a73a7ee4d454f835ba63da3cf458f"}},"c8435f25b9ca45c8a919bcb137b69381":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_07a9e75c28a046a6a3786d0144f0317a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4389d650d04e4621b7c6136658b061c3"}},"bb80ead12dd445c4a0728c4a4107b39f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_60d0ab4ff5a54ee8890a625c1aba04ce","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500/500 [00:29&lt;00:00, 17.74it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_186c435724da413b88e9ae0e149f1a22"}},"7cb5babce74e44bd86a2736c41803f8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"692a73a7ee4d454f835ba63da3cf458f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07a9e75c28a046a6a3786d0144f0317a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4389d650d04e4621b7c6136658b061c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60d0ab4ff5a54ee8890a625c1aba04ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"186c435724da413b88e9ae0e149f1a22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c828038862b94f08a014294cdc3ac1eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a0262dde020843b2a78fe1d8f97c6b48","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c15b1d0c17b04aca9cee10fedd99de87","IPY_MODEL_879fe8f3970c4219a2f6518449dc4f20","IPY_MODEL_3699f74b78d5427785b07b0f3e2ae4c5"]}},"a0262dde020843b2a78fe1d8f97c6b48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"c15b1d0c17b04aca9cee10fedd99de87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a1ed9934500940e2a927673986a3d18b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e7b07083926b41cd8ac0402fe8ad994b"}},"879fe8f3970c4219a2f6518449dc4f20":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_956a52ee08414e5390ff06995ab876e1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e84d7339b2e24472bd28b95fed5bddc6"}},"3699f74b78d5427785b07b0f3e2ae4c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ffaaeae6ae044e9ad248ebc402c0abf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500/500 [00:29&lt;00:00, 17.79it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe53c64476304cac8a949bfee45db7ad"}},"a1ed9934500940e2a927673986a3d18b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e7b07083926b41cd8ac0402fe8ad994b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"956a52ee08414e5390ff06995ab876e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e84d7339b2e24472bd28b95fed5bddc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ffaaeae6ae044e9ad248ebc402c0abf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fe53c64476304cac8a949bfee45db7ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b25139f24894f17941260b14101865f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_418544e373a84b3dae7942ff565ac44d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_842bfcc94be649f1ba5aaf16cc898e9c","IPY_MODEL_188fcbd8782f42e38e69e0bf22a5cb96","IPY_MODEL_5a967d3eaa04445f943e4ae76eb42872"]}},"418544e373a84b3dae7942ff565ac44d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"842bfcc94be649f1ba5aaf16cc898e9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7a1301d02f5b42f891a09d46a35b64c0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_443f2b017b164dd09523d413dd22bd9c"}},"188fcbd8782f42e38e69e0bf22a5cb96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8558af0be0de45bdb156fcfc15d87680","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_60ad44d606b1440daafad542b0f939d8"}},"5a967d3eaa04445f943e4ae76eb42872":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bd7ae154ec64407f924c83d95baf8408","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500/500 [00:29&lt;00:00, 17.59it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_225ae42308fe458a98b4855255cc8dca"}},"7a1301d02f5b42f891a09d46a35b64c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"443f2b017b164dd09523d413dd22bd9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8558af0be0de45bdb156fcfc15d87680":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"60ad44d606b1440daafad542b0f939d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd7ae154ec64407f924c83d95baf8408":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"225ae42308fe458a98b4855255cc8dca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"416a45fd91e9496dab72d645577ddf77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0e66d9e774b44464bf8b93ddc26c72fb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_04c5b3d38bdf4741baf9d744376c6244","IPY_MODEL_46bafa1b3d764b13b31dae61ba148d59","IPY_MODEL_6ff7ad282e184091be35b7c7af417c09"]}},"0e66d9e774b44464bf8b93ddc26c72fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"04c5b3d38bdf4741baf9d744376c6244":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_82a9c5b1990a4ef0ab95f9b846d82968","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_67674d84431e47e2a84a2762809cf6de"}},"46bafa1b3d764b13b31dae61ba148d59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_523c5dacbbfd4a75a6ecfc1cd1bc4dce","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8400810ed09d43dfb2830f252d0d448a"}},"6ff7ad282e184091be35b7c7af417c09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_22bfa5ee19c8461f8199bb1eba6ab357","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500/500 [00:29&lt;00:00, 17.48it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f8264247bab47f497a860859b2a455e"}},"82a9c5b1990a4ef0ab95f9b846d82968":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"67674d84431e47e2a84a2762809cf6de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"523c5dacbbfd4a75a6ecfc1cd1bc4dce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8400810ed09d43dfb2830f252d0d448a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22bfa5ee19c8461f8199bb1eba6ab357":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2f8264247bab47f497a860859b2a455e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a2b0f6042da4862b1d1bc00c8d853ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a0516e37547b4ac4a106fb6730026515","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_926e6b70d9074273b84ac596d2f2d856","IPY_MODEL_b7854ec8f269451ebeb52be0b1816c22","IPY_MODEL_bcf7a8f8462f4074952799f4f0411bc8"]}},"a0516e37547b4ac4a106fb6730026515":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"926e6b70d9074273b84ac596d2f2d856":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cf8e6048cb4a48f1af3c1d896027a594","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee006b4437c54ce7bee60db01ff6fc25"}},"b7854ec8f269451ebeb52be0b1816c22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_68e99d24abf3448596eb96ca6c33ba30","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_03b1191715264ff3aa43bdcdb52ce358"}},"bcf7a8f8462f4074952799f4f0411bc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_03f0380aac924ff393a654c674938598","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500/500 [00:29&lt;00:00, 17.65it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c2c1736a3bdc46c7a28e17eec53fd2c1"}},"cf8e6048cb4a48f1af3c1d896027a594":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ee006b4437c54ce7bee60db01ff6fc25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"68e99d24abf3448596eb96ca6c33ba30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"03b1191715264ff3aa43bdcdb52ce358":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03f0380aac924ff393a654c674938598":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c2c1736a3bdc46c7a28e17eec53fd2c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cf60dc5dab254254a03041f2a80c094f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bc7db7d715074663a1c28195f289e41f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1565ce76a76149bdb112154d1c633c86","IPY_MODEL_bc4413f5564641479139732dfe1dbc26","IPY_MODEL_c5323b63d2694d03bd3f407d6ea15f4d"]}},"bc7db7d715074663a1c28195f289e41f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"1565ce76a76149bdb112154d1c633c86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef894d4a3a1a4db19f367951d5514c1d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6dd9db4837a549cab869280a3636cc2b"}},"bc4413f5564641479139732dfe1dbc26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5ff2195c8941402b9e15055997d3d153","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74b77c3d43034d8b8a7c32a3d026a594"}},"c5323b63d2694d03bd3f407d6ea15f4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea7c86272d2e4f348cd0660d506170af","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500/500 [00:29&lt;00:00, 17.58it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_606532cb09ed413e83db4a175ce42e47"}},"ef894d4a3a1a4db19f367951d5514c1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6dd9db4837a549cab869280a3636cc2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ff2195c8941402b9e15055997d3d153":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"74b77c3d43034d8b8a7c32a3d026a594":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea7c86272d2e4f348cd0660d506170af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"606532cb09ed413e83db4a175ce42e47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"442c0aa2dccb4992bcdc55cdc9b29ba2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9c739c85abb3405691cf7a4b1ade181e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_80f83666457948d7be9e25268142e42f","IPY_MODEL_40ab86fcce094fbfa227986b444d4112","IPY_MODEL_abee7d057cb6439e9e9ab1b0c82015a0"]}},"9c739c85abb3405691cf7a4b1ade181e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"80f83666457948d7be9e25268142e42f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2d20ed3508aa4aa2865b8408f52893aa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Testing: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0d8373886d3d444d94c9d1e513f4d420"}},"40ab86fcce094fbfa227986b444d4112":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2a9a8e9d3df441128c9e4ad336917c95","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a8714bf8b00347de8f97f7e88a94bfab"}},"abee7d057cb6439e9e9ab1b0c82015a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7d883a2bb72342cba7209a6abd6f24bd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 125/125 [01:56&lt;00:00,  1.14it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd5e96c49b0142c29f9fb8f1152d4ed3"}},"2d20ed3508aa4aa2865b8408f52893aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0d8373886d3d444d94c9d1e513f4d420":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2a9a8e9d3df441128c9e4ad336917c95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a8714bf8b00347de8f97f7e88a94bfab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d883a2bb72342cba7209a6abd6f24bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dd5e96c49b0142c29f9fb8f1152d4ed3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0fb21449189e4c61975e1d9d290d6cef":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_59355890bb6f4d07bf0c3d5569d1ee41","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_85d7f0afd0d74979a03a45e1f796444a","IPY_MODEL_174651e442f3426ab6ee81ce7696014f"]}},"59355890bb6f4d07bf0c3d5569d1ee41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"85d7f0afd0d74979a03a45e1f796444a":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_c361f7c54abc4b64b52d4ec48bf7180d","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 692.87MB of 692.87MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a03abc32939432295f3565297ae0077"}},"174651e442f3426ab6ee81ce7696014f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7c9448a5901b44938a2e23795d9f0979","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_478a5f483add4f96ad39dca0613b9b02"}},"c361f7c54abc4b64b52d4ec48bf7180d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8a03abc32939432295f3565297ae0077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c9448a5901b44938a2e23795d9f0979":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"478a5f483add4f96ad39dca0613b9b02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t670509TFmh9","executionInfo":{"status":"ok","timestamp":1630849996371,"user_tz":-540,"elapsed":220,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}},"outputId":"6e1f0c53-6cb2-4c17-85ec-510f5be5f63e"},"source":["cd /content/drive/MyDrive/ColabNotebooks/Research/KG2QGwithT5/adjacencyattentionwithoutselfloop"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabNotebooks/Research/KG2QGwithT5/adjacencyattentionwithoutselfloop\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4stmmOVYG8o8","executionInfo":{"status":"ok","timestamp":1629707034730,"user_tz":-540,"elapsed":447,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}},"outputId":"1a41e118-4b5c-452e-99d6-99b2a65855b4"},"source":["!git init"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Initialized empty Git repository in /content/drive/MyDrive/ColabNotebooks/Research/KG2QGwithT5/adjacencyattentionwithoutselfloop/.git/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N9wPK4AzG-Zo"},"source":["!git add ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_--75isXHAYd"},"source":["!git commit -m \"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X3uslLVfN9jc"},"source":["# t5-small web question"]},{"cell_type":"markdown","metadata":{"id":"nm1_keQbUmXt"},"source":["## Install dependency\n","~~~\n","Based on the pyproject.toml in the current path, dependency will be installed in order.\n","~~~"]},{"cell_type":"code","metadata":{"id":"ANkDS-rHUeq4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630825060516,"user_tz":-540,"elapsed":8082,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}},"outputId":"9b867d1a-807f-4f86-8b38-3df85891b9e0"},"source":["!pip install -q --pre poetry==1.1.8"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 71 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 163 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 173 kB 8.2 MB/s \n","\u001b[K     |████████████████████████████████| 54 kB 3.5 MB/s \n","\u001b[K     |████████████████████████████████| 5.3 MB 69.6 MB/s \n","\u001b[K     |████████████████████████████████| 91 kB 7.4 MB/s \n","\u001b[K     |████████████████████████████████| 40 kB 7.4 MB/s \n","\u001b[K     |████████████████████████████████| 420 kB 69.8 MB/s \n","\u001b[K     |████████████████████████████████| 54 kB 3.2 MB/s \n","\u001b[K     |████████████████████████████████| 3.0 MB 70.9 MB/s \n","\u001b[K     |████████████████████████████████| 338 kB 84.3 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"KtjDZD5DUp7t","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1630825209261,"user_tz":-540,"elapsed":148753,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}},"outputId":"ce54d388-3d95-4fa0-bbf8-cfefcba4f0f4"},"source":["!pip install --requirement <(poetry export --format requirements.txt)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ignoring colorama: markers 'python_version >= \"3.6\" and python_full_version < \"3.0.0\" and platform_system == \"Windows\" or python_full_version >= \"3.5.0\" and python_version >= \"3.6\" and platform_system == \"Windows\"' don't match your environment\n","Ignoring pywin32: markers 'sys_platform == \"win32\" and python_version >= \"3.6\"' don't match your environment\n","Ignoring waitress: markers 'platform_system == \"Windows\" and python_version >= \"3.6\" and python_full_version >= \"3.6.0\"' don't match your environment\n","Collecting absl-py==0.13.0\n","  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 8.3 MB/s \n","\u001b[?25hCollecting aiohttp==3.7.4.post0\n","  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 70.7 MB/s \n","\u001b[?25hCollecting alembic==1.4.1\n","  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 54.3 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 74.2 MB/s \n","\u001b[?25hCollecting async-timeout==3.0.1\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: attrs==21.2.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 49)) (21.2.0)\n","Requirement already satisfied: cachetools==4.2.2 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 52)) (4.2.2)\n","Requirement already satisfied: certifi==2021.5.30 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 55)) (2021.5.30)\n","Collecting chardet==4.0.0\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[K     |████████████████████████████████| 178 kB 83.8 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer==2.0.4 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 61)) (2.0.4)\n","Collecting click==8.0.1\n","  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 8.7 MB/s \n","\u001b[?25hCollecting cloudpickle==1.6.0\n","  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n","Collecting configparser==5.0.2\n","  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n","Collecting databricks-cli==0.15.0\n","  Downloading databricks-cli-0.15.0.tar.gz (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 5.9 MB/s \n","\u001b[?25hCollecting docker-pycreds==0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting docker==5.0.2\n","  Downloading docker-5.0.2-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 78.8 MB/s \n","\u001b[?25hRequirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 85)) (0.3)\n","Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 88)) (3.0.12)\n","Collecting flask==2.0.1\n","  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.8 MB/s \n","\u001b[?25hCollecting fsspec==2021.8.1\n","  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n","\u001b[K     |████████████████████████████████| 119 kB 81.5 MB/s \n","\u001b[?25hCollecting future==0.18.2\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 73.7 MB/s \n","\u001b[?25hCollecting gitdb==4.0.7\n","  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n","\u001b[?25hCollecting gitpython==3.1.20\n","  Downloading GitPython-3.1.20-py3-none-any.whl (178 kB)\n","\u001b[K     |████████████████████████████████| 178 kB 69.4 MB/s \n","\u001b[?25hCollecting google-auth-oauthlib==0.4.6\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Collecting google-auth==1.35.0\n","  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n","\u001b[K     |████████████████████████████████| 152 kB 73.1 MB/s \n","\u001b[?25hRequirement already satisfied: greenlet==1.1.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 111)) (1.1.1)\n","Requirement already satisfied: grpcio==1.39.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 162)) (1.39.0)\n","Collecting gunicorn==20.1.0\n","  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 10.6 MB/s \n","\u001b[?25hCollecting hydra-core==1.1.1\n","  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 59.2 MB/s \n","\u001b[?25hCollecting hydra==2.5\n","  Downloading Hydra-2.5.tar.gz (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 658 kB/s \n","\u001b[?25hCollecting idna==3.2\n","  Downloading idna-3.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 8.0 MB/s \n","\u001b[?25hCollecting importlib-metadata==4.8.1\n","  Downloading importlib_metadata-4.8.1-py3-none-any.whl (17 kB)\n","Requirement already satisfied: importlib-resources==5.2.2 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 228)) (5.2.2)\n","Collecting itsdangerous==2.0.1\n","  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n","Collecting jinja2==3.0.1\n","  Downloading Jinja2-3.0.1-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 90.0 MB/s \n","\u001b[?25hRequirement already satisfied: joblib==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 237)) (1.0.1)\n","Collecting mako==1.1.5\n","  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 6.1 MB/s \n","\u001b[?25hRequirement already satisfied: markdown==3.3.4 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 243)) (3.3.4)\n","Requirement already satisfied: markupsafe==2.0.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 246)) (2.0.1)\n","Collecting mlflow==1.20.2\n","  Downloading mlflow-1.20.2-py3-none-any.whl (14.6 MB)\n","\u001b[K     |████████████████████████████████| 14.6 MB 72.6 MB/s \n","\u001b[?25hCollecting multidict==5.1.0\n","  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n","\u001b[K     |████████████████████████████████| 142 kB 76.4 MB/s \n","\u001b[?25hCollecting nltk==3.6\n","  Downloading nltk-3.6-py3-none-any.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 59.2 MB/s \n","\u001b[?25hCollecting numpy==1.21.1\n","  Downloading numpy-1.21.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 132 kB/s \n","\u001b[?25hRequirement already satisfied: oauthlib==3.1.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 374)) (3.1.1)\n","Collecting omegaconf==2.1.1\n","  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 4.1 MB/s \n","\u001b[?25hCollecting packaging==21.0\n","  Downloading packaging-21.0-py3-none-any.whl (40 kB)\n","\u001b[K     |████████████████████████████████| 40 kB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 383)) (1.1.5)\n","Collecting pillow==8.3.2\n","  Downloading Pillow-8.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 76.1 MB/s \n","\u001b[?25hRequirement already satisfied: prometheus-client==0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 462)) (0.11.0)\n","Collecting prometheus-flask-exporter==0.18.2\n","  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\n","Requirement already satisfied: promise==2.3 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 467)) (2.3)\n","Requirement already satisfied: protobuf==3.17.3 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 469)) (3.17.3)\n","Collecting psutil==5.8.0\n","  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n","\u001b[K     |████████████████████████████████| 296 kB 76.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 526)) (0.2.8)\n","Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 540)) (0.4.8)\n","Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 554)) (2.4.7)\n","Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 557)) (2.8.2)\n","Collecting python-editor==1.0.4\n","  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n","Collecting pytorch-lightning==1.2.1\n","  Downloading pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n","\u001b[K     |████████████████████████████████| 814 kB 56.3 MB/s \n","\u001b[?25hCollecting pytz==2021.1\n","  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n","\u001b[K     |████████████████████████████████| 510 kB 83.7 MB/s \n","\u001b[?25hCollecting pyyaml==5.3.1\n","  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n","\u001b[K     |████████████████████████████████| 269 kB 94.2 MB/s \n","\u001b[?25hCollecting querystring-parser==1.2.4\n","  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n","Collecting regex==2021.8.28\n","  Downloading regex-2021.8.28-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (745 kB)\n","\u001b[K     |████████████████████████████████| 745 kB 64.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 644)) (1.3.0)\n","Collecting requests==2.26.0\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.0 MB/s \n","\u001b[?25hRequirement already satisfied: rsa==4.7.2 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 651)) (4.7.2)\n","Collecting sacremoses==0.0.45\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 67.9 MB/s \n","\u001b[?25hCollecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 66.5 MB/s \n","\u001b[?25hCollecting sentry-sdk==1.3.1\n","  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 91.9 MB/s \n","\u001b[?25hCollecting shortuuid==1.0.1\n","  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n","Collecting six==1.16.0\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting smmap==4.0.0\n","  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n","Collecting sqlalchemy==1.4.23\n","  Downloading SQLAlchemy-1.4.23-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 61.0 MB/s \n","\u001b[?25hRequirement already satisfied: sqlparse==0.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 743)) (0.4.1)\n","Collecting subprocess32==3.5.4\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: tabulate==0.8.9 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 750)) (0.8.9)\n","Requirement already satisfied: tensorboard-data-server==0.6.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 753)) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 757)) (1.8.0)\n","Requirement already satisfied: tensorboard==2.6.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 759)) (2.6.0)\n","Collecting torch==1.7.1\n","  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n","\u001b[K     |████████████████████████████████| 776.8 MB 12 kB/s \n","\u001b[?25hCollecting torchtext==0.8.0\n","  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n","\u001b[K     |████████████████████████████████| 6.9 MB 11.0 MB/s \n","\u001b[?25hCollecting torchvision==0.8.2\n","  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n","\u001b[K     |████████████████████████████████| 12.8 MB 21.0 MB/s \n","\u001b[?25hCollecting tqdm==4.62.2\n","  Downloading tqdm-4.62.2-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 5.9 MB/s \n","\u001b[?25hCollecting typing-extensions==3.10.0.2\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Collecting urllib3==1.26.6\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 91.7 MB/s \n","\u001b[?25hCollecting wandb==0.10.7\n","  Downloading wandb-0.10.7-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 89.9 MB/s \n","\u001b[?25hCollecting watchdog==2.1.5\n","  Downloading watchdog-2.1.5-py3-none-manylinux2014_x86_64.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 5.5 MB/s \n","\u001b[?25hCollecting websocket-client==1.2.1\n","  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.8 MB/s \n","\u001b[?25hCollecting werkzeug==2.0.1\n","  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n","\u001b[K     |████████████████████████████████| 288 kB 83.2 MB/s \n","\u001b[?25hCollecting yarl==1.6.3\n","  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 69.9 MB/s \n","\u001b[?25hRequirement already satisfied: zipp==3.5.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 874)) (3.5.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.35.0->-r /dev/fd/63 (line 108)) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.6.0->-r /dev/fd/63 (line 759)) (0.37.0)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'gitpython' candidate (version 3.1.20 at https://files.pythonhosted.org/packages/55/60/f884f01eef2a7255875862ec1b12d57d74113ec6e8d9e16c4d254cd6aa3c/GitPython-3.1.20-py3-none-any.whl#sha256=b1e1c269deab1b08ce65403cf14e10d2ef1f6c89e33ea7c5e5bb0222ea593b8a (from https://pypi.org/simple/gitpython/) (requires-python:>=3.6))\n","Reason for being yanked: Issues with typing of ordered dict\u001b[0m\n","Building wheels for collected packages: alembic, antlr4-python3-runtime, databricks-cli, future, hydra, prometheus-flask-exporter, pyyaml, subprocess32\n","  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158172 sha256=c8be44fe37c1ea7a949ad43533de5cfed885fe3e0c39c06d57456f3dcc3d5a41\n","  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=4f07ce433d94a3a121e2452bcd8d94ed6d9fa9084cd9b0d4c980ec6174b36894\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for databricks-cli: filename=databricks_cli-0.15.0-py3-none-any.whl size=105260 sha256=42b2b80b2b75946ac4f987d2d15f70b46200283380852efaa73cea7411be4504\n","  Stored in directory: /root/.cache/pip/wheels/e7/ba/75/284f9a90ff7a010bb23b9798f2e9a19dd9fe619379c917bff4\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=be7e3e52dc9cea3d2b2aa7d75519743a05ef87ab76a3c326bbebb9137926df34\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.5-cp37-cp37m-linux_x86_64.whl size=220767 sha256=b6843650d296377ee37f00e54f1f1b4258605badbc5358aa0c1b8c6331c70e66\n","  Stored in directory: /root/.cache/pip/wheels/46/28/7d/3b38a41d900da90c4e17576f442bac9344eb1f5a4e78ee9f83\n","  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17415 sha256=684ce65ed941572d3e460e04328cd791705d11c0d9170eaed161573a91b5805e\n","  Stored in directory: /root/.cache/pip/wheels/6a/1e/1c/c765920cb92b2f0343d2dd8b481a407cee2823f9b4bbd2e52a\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44635 sha256=93a3433706a08087144a01c90c2d47662c1d749825125d1069e65e8fbba92ad7\n","  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=ccf8733547cc92c861a8e2dd6b317a37b62b1efff8c896d5658a6eafb43046c9\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","Successfully built alembic antlr4-python3-runtime databricks-cli future hydra prometheus-flask-exporter pyyaml subprocess32\n","Installing collected packages: urllib3, typing-extensions, idna, six, requests, multidict, importlib-metadata, yarl, werkzeug, smmap, jinja2, itsdangerous, google-auth, click, chardet, async-timeout, websocket-client, sqlalchemy, pyyaml, pytz, python-editor, numpy, mako, google-auth-oauthlib, gitdb, fsspec, flask, antlr4-python3-runtime, aiohttp, absl-py, watchdog, tqdm, torch, subprocess32, shortuuid, sentry-sdk, regex, querystring-parser, psutil, prometheus-flask-exporter, pillow, packaging, omegaconf, gunicorn, gitpython, future, docker-pycreds, docker, databricks-cli, configparser, cloudpickle, alembic, wandb, torchvision, torchtext, sentencepiece, sacremoses, pytorch-lightning, nltk, mlflow, hydra-core, hydra\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 3.7.4.3\n","    Uninstalling typing-extensions-3.7.4.3:\n","      Successfully uninstalled typing-extensions-3.7.4.3\n","  Attempting uninstall: idna\n","    Found existing installation: idna 2.10\n","    Uninstalling idna-2.10:\n","      Successfully uninstalled idna-2.10\n","  Attempting uninstall: six\n","    Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 1.7.0\n","    Uninstalling importlib-metadata-1.7.0:\n","      Successfully uninstalled importlib-metadata-1.7.0\n","  Attempting uninstall: werkzeug\n","    Found existing installation: Werkzeug 1.0.1\n","    Uninstalling Werkzeug-1.0.1:\n","      Successfully uninstalled Werkzeug-1.0.1\n","  Attempting uninstall: jinja2\n","    Found existing installation: Jinja2 2.11.3\n","    Uninstalling Jinja2-2.11.3:\n","      Successfully uninstalled Jinja2-2.11.3\n","  Attempting uninstall: itsdangerous\n","    Found existing installation: itsdangerous 1.1.0\n","    Uninstalling itsdangerous-1.1.0:\n","      Successfully uninstalled itsdangerous-1.1.0\n","  Attempting uninstall: google-auth\n","    Found existing installation: google-auth 1.34.0\n","    Uninstalling google-auth-1.34.0:\n","      Successfully uninstalled google-auth-1.34.0\n","  Attempting uninstall: click\n","    Found existing installation: click 7.1.2\n","    Uninstalling click-7.1.2:\n","      Successfully uninstalled click-7.1.2\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 3.0.4\n","    Uninstalling chardet-3.0.4:\n","      Successfully uninstalled chardet-3.0.4\n","  Attempting uninstall: sqlalchemy\n","    Found existing installation: SQLAlchemy 1.4.22\n","    Uninstalling SQLAlchemy-1.4.22:\n","      Successfully uninstalled SQLAlchemy-1.4.22\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pytz\n","    Found existing installation: pytz 2018.9\n","    Uninstalling pytz-2018.9:\n","      Successfully uninstalled pytz-2018.9\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 0.4.5\n","    Uninstalling google-auth-oauthlib-0.4.5:\n","      Successfully uninstalled google-auth-oauthlib-0.4.5\n","  Attempting uninstall: flask\n","    Found existing installation: Flask 1.1.4\n","    Uninstalling Flask-1.1.4:\n","      Successfully uninstalled Flask-1.1.4\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 0.12.0\n","    Uninstalling absl-py-0.12.0:\n","      Successfully uninstalled absl-py-0.12.0\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.62.0\n","    Uninstalling tqdm-4.62.0:\n","      Successfully uninstalled tqdm-4.62.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","  Attempting uninstall: regex\n","    Found existing installation: regex 2019.12.20\n","    Uninstalling regex-2019.12.20:\n","      Successfully uninstalled regex-2019.12.20\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 20.9\n","    Uninstalling packaging-20.9:\n","      Successfully uninstalled packaging-20.9\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.10.0+cu102\n","    Uninstalling torchvision-0.10.0+cu102:\n","      Successfully uninstalled torchvision-0.10.0+cu102\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.10.0\n","    Uninstalling torchtext-0.10.0:\n","      Successfully uninstalled torchtext-0.10.0\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.1 which is incompatible.\n","tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\n","tensorflow-metadata 1.2.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.13.0 which is incompatible.\n","poetry 1.1.8 requires importlib-metadata<2.0.0,>=1.6.0; python_version < \"3.8\", but you have importlib-metadata 4.8.1 which is incompatible.\n","poetry 1.1.8 requires packaging<21.0,>=20.4, but you have packaging 21.0 which is incompatible.\n","poetry-core 1.0.4 requires importlib-metadata<2.0.0,>=1.7.0; python_version >= \"2.7\" and python_version < \"2.8\" or python_version >= \"3.5\" and python_version < \"3.8\", but you have importlib-metadata 4.8.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed absl-py-0.13.0 aiohttp-3.7.4.post0 alembic-1.4.1 antlr4-python3-runtime-4.8 async-timeout-3.0.1 chardet-4.0.0 click-8.0.1 cloudpickle-1.6.0 configparser-5.0.2 databricks-cli-0.15.0 docker-5.0.2 docker-pycreds-0.4.0 flask-2.0.1 fsspec-2021.8.1 future-0.18.2 gitdb-4.0.7 gitpython-3.1.20 google-auth-1.35.0 google-auth-oauthlib-0.4.6 gunicorn-20.1.0 hydra-2.5 hydra-core-1.1.1 idna-3.2 importlib-metadata-4.8.1 itsdangerous-2.0.1 jinja2-3.0.1 mako-1.1.5 mlflow-1.20.2 multidict-5.1.0 nltk-3.6 numpy-1.21.1 omegaconf-2.1.1 packaging-21.0 pillow-8.3.2 prometheus-flask-exporter-0.18.2 psutil-5.8.0 python-editor-1.0.4 pytorch-lightning-1.2.1 pytz-2021.1 pyyaml-5.3.1 querystring-parser-1.2.4 regex-2021.8.28 requests-2.26.0 sacremoses-0.0.45 sentencepiece-0.1.96 sentry-sdk-1.3.1 shortuuid-1.0.1 six-1.16.0 smmap-4.0.0 sqlalchemy-1.4.23 subprocess32-3.5.4 torch-1.7.1 torchtext-0.8.0 torchvision-0.8.2 tqdm-4.62.2 typing-extensions-3.10.0.2 urllib3-1.26.6 wandb-0.10.7 watchdog-2.1.5 websocket-client-1.2.1 werkzeug-2.0.1 yarl-1.6.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","google","numpy","psutil","pydevd_plugins","pytz","six"]}}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"ugAwfoQ_bdxJ"},"source":["## Import Library"]},{"cell_type":"code","metadata":{"id":"wjnysYHObfVr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630838134283,"user_tz":-540,"elapsed":30921,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}},"outputId":"51e482e1-ff43-455e-9dac-c2dde6d9cb00"},"source":["import argparse\n","import glob\n","import os\n","import json\n","import time\n","import logging\n","import random\n","import re\n","from itertools import chain\n","from string import punctuation\n"," \n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import pytorch_lightning as pl\n","\n","import io\n","import string\n","from collections import Counter, defaultdict, OrderedDict\n","from nltk.tokenize import wordpunct_tokenize, word_tokenize\n"," \n","import gc\n","\n","from AdjacencyAttentionWithoutSelfloopTransformers import (\n","  AdamW,\n","  T5ForConditionalGeneration,\n","  T5Tokenizer,\n","  get_linear_schedule_with_warmup\n",")\n","\n","import os.path\n","\n","import wandb\n","wandb.login()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmacho000\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"tYMoF8WByP29"},"source":["## Preprocess"]},{"cell_type":"code","metadata":{"id":"epRZ6fwI0COD"},"source":["def preprocess_wq(config):\n","    if not os.path.isfile(\"processed/mhqg-wq/SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-wq/SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-wq/SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-wq/TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-wq/TARGET_MASK_memmap.npy\"\n","        # input_length = 18624\n","        input_length = 18989\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-wq/train.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","                n = len(jo['inGraph']['g_node_names'])\n","                adj_matrix = {}\n","                adj_matrix2 = {}\n","                graph = {'node_name_id2word':{}}\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        edge = edge.split('/')[-1]\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1\n","\n","    if not os.path.isfile(\"processed/mhqg-wq/VAL_SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-wq/VAL_SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-wq/VAL_SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/VAL_SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-wq/VAL_TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-wq/VAL_TARGET_MASK_memmap.npy\"\n","        # input_length = 18624\n","        input_length = 2000\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-wq/dev.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","                n = len(jo['inGraph']['g_node_names'])\n","                adj_matrix = {}\n","                adj_matrix2 = {}\n","                graph = {'node_name_id2word':{}}\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        edge = edge.split('/')[-1]\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1\n","\n","    if not os.path.isfile(\"processed/mhqg-wq/TEST_SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-wq/TEST_SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-wq/TEST_SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/TEST_SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-wq/TEST_TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-wq/TEST_TARGET_MASK_memmap.npy\"\n","        # input_length = 18624\n","        input_length = 2000\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-wq/test.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","                n = len(jo['inGraph']['g_node_names'])\n","                adj_matrix = {}\n","                adj_matrix2 = {}\n","                graph = {'node_name_id2word':{}}\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        edge = edge.split('/')[-1]\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eoLohVqp0WNa"},"source":["def preprocess_pq(config):\n","    # preprocess input data\n","    if not os.path.isfile(\"processed/mhqg-pq/SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-pq/SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-pq/SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-pq/TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-pq/TARGET_MASK_memmap.npy\"\n","        input_length = 9793\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-pq/train.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","\n","                # used for model input\n","                adj_matrix = {}\n","                # used for create adjacency matrix\n","                adj_matrix2 = {}\n","                # map from id to node name\n","                graph = {'node_name_id2word':{}}\n","\n","                # make graph mapping from id to node name\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","\n","\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1\n","\n","    # preprocess validation.json \n","    if not os.path.isfile(\"processed/mhqg-pq/VAL_SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-pq/VAL_SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-pq/VAL_SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/VAL_SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-pq/VAL_TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-pq/VAL_TARGET_MASK_memmap.npy\"\n","        input_length = 1000\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-pq/dev.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","\n","                # used for model input\n","                adj_matrix = {}\n","                # used for create adjacency matrix\n","                adj_matrix2 = {}\n","                # map from id to node name\n","                graph = {'node_name_id2word':{}}\n","\n","                # make graph mapping from id to node name\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","\n","\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1\n","\n","    # preprocess test.json\n","    if not os.path.isfile(\"processed/mhqg-pq/TEST_SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-pq/TEST_SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-pq/TEST_SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/TEST_SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-pq/TEST_TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-pq/TEST_TARGET_MASK_memmap.npy\"\n","        # input_length = 18624\n","        input_length = 1000\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-pq/test.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","\n","                # used for model input\n","                adj_matrix = {}\n","                # used for create adjacency matrix\n","                adj_matrix2 = {}\n","                # map from id to node name\n","                graph = {'node_name_id2word':{}}\n","\n","                # make graph mapping from id to node name\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","\n","\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPvozaYuGalT"},"source":["class Preprocess():\n","    def __init__(self, config):\n","        if config.experiment.data==\"mhqg-wq\":\n","            preprocess_wq(config)\n","        elif config.experiment.data==\"mhqg-pq\":\n","            preprocess_pq(config)\n","        else:\n","            raise"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e9Zs6fjH4Mx7"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"vkO8pkJm4MYm"},"source":["from torch.utils.data import Dataset\n","import numpy as np\n","import json\n","import torch\n","from collections import Counter, defaultdict, OrderedDict\n","import gc\n","import os\n","\n","class JsonDatasetWQ(Dataset):\n","    def __init__(self, tokenizer, data_dir, type_path, input_max_len=512, target_max_len=512, mode=None):\n","        assert mode==\"Train\" or mode==\"Val\" or mode==\"Test\"\n","        self.file_path = os.path.join(data_dir, type_path)\n","        \n","        self.input_max_len = input_max_len\n","        self.target_max_len = target_max_len\n","        self.tokenizer = tokenizer\n","        self.inputs = []\n","        self.targets = []\n"," \n","        self.mode = mode\n"," \n","        if mode==\"Train\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-wq/SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-wq/SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-wq/TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-wq/TARGET_MASK_memmap.npy\"\n","        #   self.input_length = 18624\n","          self.input_length = 18989\n","          self.list_index = 18989\n","        elif mode==\"Val\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-wq/VAL_SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-wq/VAL_SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/VAL_SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-wq/VAL_TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-wq/VAL_TARGET_MASK_memmap.npy\"\n","          self.input_length = 2000\n","          self.list_index = 2000\n","        #   self.input_length = 1985\n","        elif mode==\"Test\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-wq/TEST_SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-wq/TEST_SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/TEST_SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-wq/TEST_TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-wq/TEST_TARGET_MASK_memmap.npy\"\n","          self.input_length = 2000\n","          self.list_index = 2000\n","          \n","        #   self.input_length = 1985\n"," \n","        self.SOURCE_ID_memmap = np.memmap(\n","          filename=self.SOURCE_ID_PATH, dtype=np.int64, mode=\"r\",shape=(self.input_length,512) \n","        )\n"," \n","        self.SOURCE_MASK_memmap = np.memmap(\n","          filename=self.SOURCE_MASK_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,512,512)\n","        )\n","\n","        self.VAL_SOURCE_CROSS_MASK_memmap = np.memmap(\n","          filename=self.SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,512)\n","        )\n"," \n","        self.TARGET_ID_memmap = np.memmap(\n","          filename=self.TARGET_ID_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,100)\n","        )\n"," \n","        self.TARGET_MASK_memmap = np.memmap(\n","          filename=self.TARGET_MASK_PATH, dtype=np.int64, mode=\"r\",shape=(self.input_length,100)\n","        )\n","\n","  \n","    def __len__(self):\n","        return self.list_index\n","  \n","    def __getitem__(self, index):\n","        return {\"source_ids\": torch.from_numpy(np.array(self.SOURCE_ID_memmap[index])).squeeze(), \"source_mask\": torch.from_numpy(np.array(self.SOURCE_MASK_memmap[index])).squeeze(), \"cross_attention_mask\":torch.from_numpy(np.array(self.VAL_SOURCE_CROSS_MASK_memmap[index])).squeeze(),\n","                \"target_ids\": torch.from_numpy(np.array(self.TARGET_ID_memmap[index])).squeeze(), \"target_mask\": torch.from_numpy(np.array(self.TARGET_MASK_memmap[index])).squeeze()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y80ocv2Ne4M_"},"source":["from torch.utils.data import Dataset\n","import numpy as np\n","import json\n","import torch\n","from collections import Counter, defaultdict, OrderedDict\n","import gc\n","import os\n","\n","class JsonDatasetPQ(Dataset):\n","    def __init__(self, tokenizer, data_dir, type_path, input_max_len=512, target_max_len=512, mode=None):\n","        assert mode==\"Train\" or mode==\"Val\" or mode==\"Test\"\n","        self.file_path = os.path.join(data_dir, type_path)\n","        \n","        self.input_max_len = input_max_len\n","        self.target_max_len = target_max_len\n","        self.tokenizer = tokenizer\n","        self.inputs = []\n","        self.targets = []\n"," \n","        self.mode = mode\n"," \n","        if mode==\"Train\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-pq/SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-pq/SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-pq/TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-pq/TARGET_MASK_memmap.npy\"\n","          self.input_length = 9793\n","          self.list_index = 9793\n","        elif mode==\"Val\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-pq/VAL_SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-pq/VAL_SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/VAL_SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-pq/VAL_TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-pq/VAL_TARGET_MASK_memmap.npy\"\n","          self.input_length = 1000\n","          self.list_index = 1000\n","        elif mode==\"Test\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-pq/TEST_SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-pq/TEST_SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/TEST_SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-pq/TEST_TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-pq/TEST_TARGET_MASK_memmap.npy\"\n","          self.input_length = 1000\n","          self.list_index = 1000\n","          \n"," \n","        self.SOURCE_ID_memmap = np.memmap(\n","          filename=self.SOURCE_ID_PATH, dtype=np.int64, mode=\"r\",shape=(self.input_length,512) \n","        )\n"," \n","        self.SOURCE_MASK_memmap = np.memmap(\n","          filename=self.SOURCE_MASK_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,512,512)\n","        )\n","\n","        self.VAL_SOURCE_CROSS_MASK_memmap = np.memmap(\n","          filename=self.SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,512)\n","        )\n"," \n","        self.TARGET_ID_memmap = np.memmap(\n","          filename=self.TARGET_ID_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,100)\n","        )\n"," \n","        self.TARGET_MASK_memmap = np.memmap(\n","          filename=self.TARGET_MASK_PATH, dtype=np.int64, mode=\"r\",shape=(self.input_length,100)\n","        )\n","\n","  \n","    def __len__(self):\n","        return self.list_index\n","  \n","    def __getitem__(self, index):\n","        return {\"source_ids\": torch.from_numpy(np.array(self.SOURCE_ID_memmap[index])).squeeze(), \"source_mask\": torch.from_numpy(np.array(self.SOURCE_MASK_memmap[index])).squeeze(), \"cross_attention_mask\":torch.from_numpy(np.array(self.VAL_SOURCE_CROSS_MASK_memmap[index])).squeeze(),\n","                \"target_ids\": torch.from_numpy(np.array(self.TARGET_ID_memmap[index])).squeeze(), \"target_mask\": torch.from_numpy(np.array(self.TARGET_MASK_memmap[index])).squeeze()}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eyOc0T7f5aID"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"wryQWCOb4_0H"},"source":["import pytorch_lightning as pl\n","from AdjacencyAttentionWithoutSelfloopTransformers import (\n","  AdamW,\n","  T5ForConditionalGeneration,\n","  T5Tokenizer,\n","  get_linear_schedule_with_warmup\n",")\n","from torch.utils.data import DataLoader\n","\n","from tqdm.auto import tqdm\n","\n","import pandas as pd\n","from core.evaluation.eval import QGEvalCap\n","\n","from omegaconf import DictConfig\n","\n","def saveOutputs(hparams: DictConfig, inputs: list, outputs: list, targets: list) -> None:\n","  data = pd.DataFrame(list(zip(inputs, outputs, targets)), columns =['inputs', 'outputs', 'targets'])\n","  data.to_csv(os.path.join(\"out\",hparams.experiment.model_dir.split(\"/\")[-1]+\".csv\"),index=False, header=True)\n","\n","def run_eval(target_src, decoded_text) -> dict:\n","  assert len(target_src) == len(decoded_text)\n","  eval_targets = {}\n","  eval_predictions = {}\n","  for idx in range(len(target_src)):\n","      eval_targets[idx] = [target_src[idx]]\n","      eval_predictions[idx] = [decoded_text[idx]]\n","\n","  QGEval = QGEvalCap(eval_targets, eval_predictions)\n","  scores = QGEval.evaluate()\n","  return scores\n","\n","class T5FineTuner(pl.LightningModule):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        # 事前学習済みモデルの読み込み\n","        self.model = T5ForConditionalGeneration.from_pretrained(config.experiment.model_name_or_path)\n","\n","        # トークナイザーの読み込み\n","        self.tokenizer = T5Tokenizer.from_pretrained(config.experiment.tokenizer_name_or_path, is_fast=True)\n","\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        self.save_hyperparameters()\n","\n","    def forward(self, input_ids, attention_mask=None, cross_attention_mask=None, decoder_input_ids=None, \n","                decoder_attention_mask=None, labels=None, mode=None):\n","        \"\"\"順伝搬\"\"\"\n","        return self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            cross_attention_mask=cross_attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","            labels=labels,\n","            three_dim_attention_mask=True\n","        )\n","\n","    def _step(self, batch, mode=None):\n","        \"\"\"ロス計算\"\"\"\n","        labels = batch[\"target_ids\"].detach().clone()\n","\n","        # All labels set to -100 are ignored (masked), \n","        # the loss is only computed for labels in [0, ..., config.vocab_size]\n","        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n","\n","        outputs = self(\n","            input_ids=batch[\"source_ids\"],\n","            attention_mask=batch[\"source_mask\"],\n","            cross_attention_mask=batch[\"cross_attention_mask\"],\n","            decoder_attention_mask=batch['target_mask'],\n","            labels=labels,\n","            mode=mode\n","        )\n","\n","        return outputs\n","\n","    def training_step(self, batch, batch_idx):\n","        \"\"\"訓練ステップ処理\"\"\"\n","        outputs = self._step(batch)\n","        loss = outputs[0]\n","        logit = outputs[1]\n","        # logging metrics we calculated by hand\n","        self.log('train/loss', loss, on_epoch=True)\n","        return {\"loss\": loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","        \"\"\"バリデーションステップ処理\"\"\"\n","        outputs = self._step(batch)\n","        loss = outputs[0]\n","        logit = outputs[1]\n","        self.log(\"valid/loss_epoch\", loss)  # default on val/test is on_epoch only\n","        return {\"val_loss\": loss}\n","\n","    def test_epoch_end(self, training_step_outputs):\n","        saveOutputs(self.config, self.inputs, self.outputs, self.targets)\n","        scores = run_eval(self.targets, self.outputs)\n","        wandb.log(scores)\n","\n","    def configure_optimizers(self):\n","        \"\"\"オプティマイザーとスケジューラーを作成する\"\"\"\n","        model = self.model\n","        no_decay = [\"bias\", \"LayerNorm.weight\"]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [p for n, p in model.named_parameters() \n","                            if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": self.config.training.weight_decay,\n","            },\n","            {\n","                \"params\": [p for n, p in model.named_parameters() \n","                            if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters, \n","                          lr=self.config.training.learning_rate, \n","                          eps=self.config.training.adam_epsilon)\n","        self.optimizer = optimizer\n","\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=self.config.training.warmup_steps, \n","            num_training_steps=self.t_total\n","        )\n","        self.scheduler = scheduler\n","\n","        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}]\n","\n","    def get_dataset(self, tokenizer, type_path, args, mode=None):\n","        \"\"\"データセットを作成する\"\"\"\n","        if args.experiment.data==\"mhqg-wq\":\n","          return JsonDatasetWQ(\n","            tokenizer=tokenizer, \n","            data_dir=args.experiment.data_dir, \n","            type_path=type_path, \n","            input_max_len=args.model.max_input_length,\n","            target_max_len=args.model.max_target_length,\n","            mode=mode)\n","        else:\n","          return JsonDatasetPQ(\n","            tokenizer=tokenizer, \n","            data_dir=args.experiment.data_dir, \n","            type_path=type_path, \n","            input_max_len=args.model.max_input_length,\n","            target_max_len=args.model.max_target_length,\n","            mode=mode)\n","    \n","    def setup(self, stage=None):\n","        \"\"\"初期設定（データセットの読み込み）\"\"\"\n","        if stage == 'fit' or stage is None:\n","            train_dataset = self.get_dataset(tokenizer=self.tokenizer, \n","                                             type_path=\"train.json\", args=self.config, mode=\"Train\")\n","            self.train_dataset = train_dataset\n","\n","            val_dataset = self.get_dataset(tokenizer=self.tokenizer, \n","                                           type_path=\"dev.json\", args=self.config, mode=\"Val\")\n","            self.val_dataset = val_dataset\n","\n","            self.t_total = (\n","                (len(train_dataset) // (self.config.training.train_batch_size * max(1, self.config.training.n_gpu)))\n","                // self.config.training.gradient_accumulation_steps\n","                * float(self.config.training.num_train_epochs)\n","            )\n","        elif stage == 'test':\n","            val_dataset = self.get_dataset(tokenizer=self.tokenizer, \n","                                           type_path=\"test.json\", args=self.config, mode=\"Test\")\n","            self.test_dataset = test_dataset\n","\n","    def train_dataloader(self):\n","        \"\"\"訓練データローダーを作成する\"\"\"\n","        return DataLoader(self.train_dataset, \n","                          batch_size=self.config.training.train_batch_size, \n","                          drop_last=True, shuffle=True, num_workers=4)\n","\n","    def val_dataloader(self):\n","        \"\"\"バリデーションデータローダーを作成する\"\"\"\n","        return DataLoader(self.val_dataset, \n","                          batch_size=self.config.training.eval_batch_size, \n","                          num_workers=4)\n","        \n","    def test_dataloader(self):\n","        \"\"\"バリデーションデータローダーを作成する\"\"\"\n","        return DataLoader(self.val_dataset, \n","                          batch_size=self.config.training.test_batch_size, \n","                          num_workers=4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n-EpS4gN5duK"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"T_6ZVtWOHV2R"},"source":["from AdjacencyAttentionWithoutSelfloopTransformers import (\n","  AdamW,\n","  T5ForConditionalGeneration,\n","  T5Tokenizer,\n","  get_linear_schedule_with_warmup\n",")\n","from torch.utils.data import DataLoader\n","\n","from tqdm.auto import tqdm\n","\n","import pandas as pd\n","from core.evaluation.eval import QGEvalCap\n","\n","from omegaconf import DictConfig\n","\n","\n","# OmegaConf.register_new_resolver(\"now\", lambda pattern: strftime(pattern, localtime()))\n","\n","def saveOutputs(hparams: DictConfig, inputs: list, outputs: list, targets: list) -> None:\n","  data = pd.DataFrame(list(zip(inputs, outputs, targets)), columns =['inputs', 'outputs', 'targets'])\n","  data.to_csv(os.path.join(\"out\",hparams.experiment.model_dir.split(\"/\")[-1]+\".csv\"),index=False, header=True)\n","\n","def run_eval(target_src, decoded_text) -> dict:\n","  assert len(target_src) == len(decoded_text)\n","  eval_targets = {}\n","  eval_predictions = {}\n","  for idx in range(len(target_src)):\n","      eval_targets[idx] = [target_src[idx]]\n","      eval_predictions[idx] = [decoded_text[idx]]\n","\n","  QGEval = QGEvalCap(eval_targets, eval_predictions)\n","  scores = QGEval.evaluate()\n","  return scores\n","\n","class T5Evaluation(pl.LightningModule):\n","    def __init__(self, config: DictConfig, train_params: DictConfig):\n","        super().__init__()\n","        self.config = config\n","        self.train_params = train_params\n","        # 事前学習済みモデルの読み込み\n","        self.model = T5ForConditionalGeneration.from_pretrained(self.config.experiment.model_dir)\n","\n","        # トークナイザーの読み込み\n","        self.tokenizer = T5Tokenizer.from_pretrained(self.config.experiment.model_dir, is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        self.save_hyperparameters()\n","\n","        self.inputs = []\n","        self.outputs = []\n","        self.targets = []\n","\n","\n","    def forward(self, input_ids, attention_mask=None, cross_attention_mask=None, decoder_input_ids=None, \n","                decoder_attention_mask=None, labels=None):\n","        \"\"\"順伝搬\"\"\"\n","        return self.model.generate(input_ids=input_ids, \n","            attention_mask=attention_mask, \n","            cross_attention_mask=cross_attention_mask,\n","            max_length=self.config.model.max_target_length,\n","            temperature=1.0,          # 生成にランダム性を入れる温度パラメータ\n","            repetition_penalty=1.5,   # 同じ文の繰り返し（モード崩壊）へのペナルティ\n","            three_dim_attention_mask=True\n","            )\n","\n","    def _step(self, batch):\n","        \"\"\"ロス計算\"\"\"\n","        labels = batch[\"target_ids\"]\n","\n","        # All labels set to -100 are ignored (masked), \n","        # the loss is only computed for labels in [0, ..., config.vocab_size]\n","        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n","\n","        outputs = self(\n","            input_ids=batch[\"source_ids\"],\n","            attention_mask=batch[\"source_mask\"],\n","            cross_attention_mask=batch[\"cross_attention_mask\"],\n","            decoder_attention_mask=batch['target_mask'],\n","            labels=labels\n","        )\n","\n","        return outputs\n","\n","    def test_step(self, batch, batch_idx):\n","        \"\"\"テストステップ処理\"\"\"\n","        output = self._step(batch)\n","        labels = batch[\"target_ids\"]\n","        labels[labels[:, :] == -100] = 0\n","        output_text = [self.tokenizer.decode(ids, skip_special_tokens=True, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in output]\n","        target_text = [self.tokenizer.decode(ids, skip_special_tokens=True, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in labels]\n","        input_text = [self.tokenizer.decode(ids, skip_special_tokens=False, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in batch[\"source_ids\"]]\n","\n","        self.inputs.extend(input_text)\n","        self.outputs.extend(output_text)\n","        self.targets.extend(target_text)\n","\n","        return {\"batch_idx\":batch_idx}\n","        \n","    \n","    def test_epoch_end(self, training_step_outputs):\n","        saveOutputs(self.config, self.inputs, self.outputs, self.targets)\n","        scores = run_eval(self.targets, self.outputs)\n","        wandb.log(scores)\n","\n","    def configure_optimizers(self):\n","        \"\"\"オプティマイザーとスケジューラーを作成する\"\"\"\n","        model = self.model\n","        no_decay = [\"bias\", \"LayerNorm.weight\"]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [p for n, p in model.named_parameters() \n","                            if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": self.config.training.weight_decay,\n","            },\n","            {\n","                \"params\": [p for n, p in model.named_parameters() \n","                            if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters, \n","                          lr=self.config.training.learning_rate, \n","                          eps=self.config.training.adam_epsilon)\n","        self.optimizer = optimizer\n","\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=self.config.training.warmup_steps, \n","            num_training_steps=self.t_total\n","        )\n","        self.scheduler = scheduler\n","\n","        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}]\n","\n","    def get_dataset(self, tokenizer, type_path, mode=None):\n","        \"\"\"データセットを作成する\"\"\"\n","        if self.config.get('experiment').data==\"mhqg-wq\":\n","          return JsonDatasetWQ(\n","            tokenizer=tokenizer, \n","            data_dir=self.config.experiment.data_dir, \n","            type_path=type_path, \n","            input_max_len=self.config.model.max_input_length,\n","            target_max_len=self.config.model.max_target_length,\n","            mode=mode)\n","        else:\n","          return JsonDatasetPQ(\n","            tokenizer=tokenizer, \n","            data_dir=self.config.experiment.data_dir, \n","            type_path=type_path, \n","            input_max_len=self.config.model.max_input_length,\n","            target_max_len=self.config.model.max_target_length,\n","            mode=mode)\n","    \n","    def setup(self, stage=None):\n","        \"\"\"初期設定（データセットの読み込み）\"\"\"\n","        if stage == 'test':\n","            test_dataset = self.get_dataset(tokenizer=self.tokenizer, \n","                                           type_path=\"test.json\", mode=\"Test\")\n","            self.test_dataset = test_dataset\n","        \n","    def test_dataloader(self):\n","        \"\"\"バリデーションデータローダーを作成する\"\"\"\n","        return DataLoader(self.test_dataset, \n","                          batch_size=self.config.training.test_batch_size, \n","                          num_workers=4)\n","\n","class Evaluation():\n","  def __init__(self, config, train_params):\n","    self.config = config\n","    self.train_params = train_params\n","\n","  def run(self):\n","    # Tokenizer\n","    tokenizer = T5Tokenizer.from_pretrained(self.config.experiment.model_dir, is_fast=True)\n","    trained_model = T5ForConditionalGeneration.from_pretrained(self.config.experiment.model_dir)\n","\n","    if self.config.experiment.data==\"mhqg-wq\":\n","        # import test data\n","        test_dataset = JsonDatasetWQ(tokenizer, self.config.experiment.data_dir, \"test.json\", \n","                                input_max_len=self.config.model.max_input_length, \n","                                target_max_len=self.config.model.max_target_length,\n","                                mode=\"Test\")\n","\n","    test_loader = DataLoader(test_dataset, batch_size=8, num_workers=4)\n","\n","    trained_model.eval()\n","\n","    inputs = []\n","    outputs = []\n","    targets = []\n","\n","    for index, batch in enumerate(tqdm(test_loader)):\n","        input_ids = batch['source_ids']\n","        input_mask = batch['source_mask']\n","        input_cross_attention_mask = batch[\"cross_attention_mask\"]\n","        if self.config.training.n_gpu:\n","            input_ids = input_ids.cuda()\n","            input_mask = input_mask.cuda()\n","\n","        output = trained_model.generate(input_ids=input_ids, \n","            attention_mask=input_mask, \n","            cross_attention_mask=input_cross_attention_mask,\n","            max_length=self.config.model.max_target_length,\n","            temperature=1.0,          # 生成にランダム性を入れる温度パラメータ\n","            repetition_penalty=1.5,   # 同じ文の繰り返し（モード崩壊）へのペナルティ\n","            three_dim_attention_mask=True\n","            )\n","\n","        output_text = [tokenizer.decode(ids, skip_special_tokens=True, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in output]\n","        target_text = [tokenizer.decode(ids, skip_special_tokens=True, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in batch[\"target_ids\"]]\n","        input_text = [tokenizer.decode(ids, skip_special_tokens=False, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in input_ids]\n","\n","        inputs.extend(input_text)\n","        outputs.extend(output_text)\n","        targets.extend(target_text)\n","\n","        saveOutputs(self.config, inputs, outputs, targets)\n","        scores = run_eval(targets, outputs)\n","        self.train_params[\"logger\"].log_metrics(scores)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q4W3UXEe4Dfh"},"source":["## Main"]},{"cell_type":"code","metadata":{"id":"5edHAbL84Gs5"},"source":["import argparse\n","import glob\n","import os\n","import json\n","import time\n","import logging\n","import random\n","from itertools import chain\n","from string import punctuation\n"," \n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","from collections import Counter, defaultdict, OrderedDict\n","from nltk.tokenize import wordpunct_tokenize, word_tokenize\n"," \n","import gc\n","\n","from omegaconf import DictConfig\n","import omegaconf\n","\n","import hydra\n","import pytorch_lightning as pl\n","\n","\n","\n","import textwrap\n","from tqdm.auto import tqdm\n","from sklearn import metrics\n","\n","from pytorch_lightning.loggers import WandbLogger\n","\n","\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n","def get_train_param(config: DictConfig) -> dict:\n","    wandb_logger = WandbLogger(\n","        name=(\"exp_\" + str(config.experiment.wandb.exp_num)),\n","        project=config.experiment.wandb.project,\n","        log_model=True,\n","    )\n","    checkpoint_path = os.path.join(\n","        config.experiment.model_dir, config.experiment.wandb.checkpoint_path\n","    )\n","    wandb_logger.log_hyperparams(config)\n","    train_params = dict(\n","        logger = wandb_logger,\n","        accumulate_grad_batches=config.training.gradient_accumulation_steps,\n","        gpus=config.training.n_gpu,\n","        max_epochs=config.training.num_train_epochs,\n","        precision= 16 if config.training.fp_16 else 32,\n","        amp_level=config.training.opt_level,\n","        gradient_clip_val=config.training.max_grad_norm,\n","    )\n","    return train_params\n","\n","# @hydra.main(config_path=\"config.yaml\")\n","def train(config: DictConfig, train_params: dict) -> None:\n","    \n","    # conduct transfer learning\n","    model = T5FineTuner(config)\n","    wandb.watch(model, log_freq=100)\n","    trainer = pl.Trainer(**train_params)\n","    trainer.fit(model)\n","\n","    model.tokenizer.save_pretrained(config.experiment.model_dir)\n","    model.model.save_pretrained(config.experiment.model_dir)\n","\n","    # trainer.test(model)\n","\n","    # torch.save(\n","    #             {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"bert-base-uncased_fold{fold}_best.pth\"\n","    #         )\n","\n","# @hydra.main(config_path=\"adjacencyattentionwithoutselfloop\", config_name=\"config\")\n","def evaluation(config: DictConfig, train_params: dict) -> None:\n","    print(\"config\",config)\n","    print(\"type_config\",type(config))\n","    set_seed(42)\n","    USE_GPU = torch.cuda.is_available()\n","    config.training.n_gpu=1 if USE_GPU else 0\n","    eval_model = T5Evaluation(config, train_params)\n","    trainer = pl.Trainer(**train_params)\n","    trainer.test(eval_model)\n","  \n","def main(config: DictConfig) -> None:\n","    if os.path.exists(config.experiment.model_dir):\n","        raise \"model_dir is exist\"\n","\n","    set_seed(42)\n","    USE_GPU = torch.cuda.is_available()\n","    config.training.n_gpu=1 if USE_GPU else 0\n","    train_params = get_train_param(config)\n","\n","    Preprocess(config)\n","    train(config, train_params)\n","    evaluation(config, train_params)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEnv3YSy4ThR","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["7da568f66ac147fba5e6f4cf5093d6d0","b6f73c325b6948b787ec12ef1ce17ee1","7a2c83e16a834dc5ad808b3c853a5cde","181e0e8023d84991b72011a8f32aaaa1","010eaeeb143b4bb58ec0a5633399817c","9ef67b35f3904947a0337d5b9a6cc716","be1f025fe5f440aab90f6c6974d57f5f","9cf4b6396f19417491bff8922ba15893","f9597c01e40c47d78f8aedbb542fd257","533f1bfb9b204fa890c9eadc195f4ad1","9af6adb75cea42f18b3ae61a8347445b","385fc4f4a1684349b96be1f2a74cef24","537c04f5c2fe4b2b93c916e21dc3c967","461f893479044fc3a8220a032af10c35","81fb7c6944de404aa37ae2db9395027b","dd7955c48b9f4344867d58ab3dee2480","86930b38a03f4a6a9eb66502cc9ba712","437061a9f4eb43a89c6d4b48a1e539d1","31a312cba4704ee49af5b0993be52ed5","842819408b05413e9dc8d7247ab9890e","0f9d62c1ba574450a602a9f497c49e36","da40de994f054d5bb43d4e0ffdde3f82","a8083708fe124deebde2df1f940cecab","4c5fe4f26fec4d37bd7aed84d2da1d85","d898bfe0cfb6451b92d8c4bdb2088ed6","ee18d4e3df2c44fb8242af3a3296dff2","7b31055307b84f63964409a5be93c319","3a4e37aab7934140bf026c843ce3ab2d","671ccf76da3d4627a8b40a469584a557","510f25f2d0eb45ee9e743606da9bf8ca","42732c62e8d9483685cbd3c183fc4317","d48a65b64bca48b7b1599386b60643c5","7aa9846c9248414fa0a5dcabc29a2fd1","a8d539825f6849b19e013dabd894a101","bf7e08793dc14986b3d039f0affd087b","0c730750e42c4f8db300d1dc8243e1d4","30bc510fc75c4eb4af7214e9309434ac","92f6e3f59a6f45d9b238e38b0a57626d","3bae42da7e0344babbdbc9f3893e1cef","3061013f00094c8d9dd677b1cdf4c0ad","2f8dbe3916074bf2a2e8c1b2037d2862","35447a73c31e4b23ae13c11adf49b320","304fb778ddbc4c979209ad553473ea4d","aefb805e2b5942d0bbb87fab715e053d","9682ed40595b49608658d5d837a9b9e5","b9cad575fc844a999e677096cee866f6","34401605a168419f88d73569fbf207cf","3d91898bed69489ea8adaa7ed317e66a","cc98e3eb1d1848f196e85ceaf34226fb","6cd407e1aa154ed099886bd6241e1954","48b50abb73594bf7818f8dfc3aa552c6","a93f2c14d6a34bfb97a6fb23d5e291a7","5f8b3f23d35f4061af33f308d3457ae9","fff3596d608348d5950e700daede7584","c8b20f2595764ea7ad2704d34200f40b","5c7530fd401a4e32987a7971070a9e4d","6797928bf035463fb6b7882a028ab13f","e150142c6d9f4a11b373972c7e56cbf5","c28f55577d024a52a36c61433074db24","1af7ce775ba440338f670d937c5edbfb","3cfa97059b8a462881e5d4b79ea9919f","c6037db488094b6c85c7dfac8bd53f02","4e0e5826c561480798448848b3b74394","9352deb504484ee5962ccf654f0baf7d","8fd42dbbcfc248ec9a2b2e169ab3a45f","9540c8e533d44a05adcba875c72d3177","75fecdcc1276491ea1b25d9df20a0974","884a0cfd41904c7a8de19b1b0387c348","b2795dae575c4609b3a649fd659eaa55","69485019139f42a8a061f9c1a7e20b80","b1a66305f2b34fb6a0e4ce1c9ac711bc","bfffe8148f0142e58fce9acd7195ba52","a6e54c25a7004a4e83804968b62dc1b6","9b3be0b2151242d4b5d707d4d109839a","406a10f47ef44a60bdbd510e556866fa","266a8114d22c4857bd48e03904f87892","a8d790bd486546f5989a6154f21cd2d9","afb6f64cb7744145bdfac4c470f21df9","4b964b0e8cce4a54979fb03c1896c69b","146abf6aaca8471e85cc467f1dd6510b","5a71e9e909704657abc696880011e133","b85cb10f89be48e898a9576886d94dc0","3afc1aaaa0f04f3baf7de43fb273e72f","b22600cfaad84991a29ca880a9518ee9","3dbdace2cab9442789c69113d74afe81","9ed1a39735e14fb0a61a2ac0876a64d8","83411bc3ece34b73b6b6471ba79ab294","301804d21e824ce3b732ee7de203d820","71f0a60bd9484a5f9aced7298e21eabd","ae88247f0b1a491e8edae040abee2536","8b3f86ac047d4fafbf84e569bd08ea0a","b0ee9d850d554c1e84158ffe8d46f46b","63f062ff8de84c43a1ae03b95921541d","730ed3e563e543ee8fc189fa28bc0a1d","2853e46926a7498ead12f4626b3e06e5","6380c96af0644de5ba338e47935deb48","32ab4949d1cc463193256abe34c71fcd","d1472da01fd34ccab511d4301d11d2ed","7baecf40614040148ea25117732d6160","14e18ba82a05401dbeb1b07ac8b4aa5f","6ae54f5fe3c54afbb24b5b3b2498c35e","2e941c632e1d43099340e2b009734e39","a19320b55100482497e45072a9c3ec85","b42882d6acbd47848ebcaf0c48a0c197","e0b7f940001e473e984dbc5c7f192892","3d27f753173c4965ac1ecc6488d4fb35","0e9ddf78e60b4babb080bc34ef00ad01","80d028505ccc49979428d841f2bb2eff","8f94d408eee44aee8faff95e12e5f931","c662fc1c5b6a4ad5985886a4905f1dc7","2ba3bee47cc84926846d3495abfb627d","6de5c51ba0c24ab891c3f95f8b671ba3","a9b4cd516d594e5db1a49a2e92b492da","6bc777c2e5a54c0e9eab31bc0408b73c","25321cff582a479ca9ab46e48d7e4061","63b5eaec9812496189f59940029e9610","e172f12440734314accad4c23828dd23","73a02320509c482ba56f91740306645b","d12153d1a3d44e4f95bc5b919671ccc0","32cbb6533aa24597b261cdc52bdd3e73","543fcba76e4b4b88b8a89726eef666e6","b3febc27bfba418b8ae11dec7592c163","7391128ca9dd4507a907416d2792e46e","e2e02dd621ec41fe838a111d16d77abe","6f0ddaec947745098c7b80b7209d6d4c","443da9428e1d49ee97d03651cc65b1e9","b872775199e049a39909cd24cec0b0ba","8107f05863f34b9f89e0151041a7e351","29d8bc2f0f354913a91efac9c79b581d"]},"executionInfo":{"status":"ok","timestamp":1630849321243,"user_tz":-540,"elapsed":11180345,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}},"outputId":"eff0c6cb-4b2f-45aa-b628-bdc0db7cb11e"},"source":["config = omegaconf.OmegaConf.load(\"config/config_wq_t5small.yaml\")\n","main(config)\n","wandb.finish()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.7<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">exp_2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/macho000/mhqg-wq_t5-small\" target=\"_blank\">https://wandb.ai/macho000/mhqg-wq_t5-small</a><br/>\n","                Run page: <a href=\"https://wandb.ai/macho000/mhqg-wq_t5-small/runs/17fwjt6z\" target=\"_blank\">https://wandb.ai/macho000/mhqg-wq_t5-small/runs/17fwjt6z</a><br/>\n","                Run data is saved locally in <code>wandb/run-20210905_103540-17fwjt6z</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: None, using: 0 TPU cores\n","\n","  | Name  | Type                       | Params\n","-----------------------------------------------------\n","0 | model | T5ForConditionalGeneration | 60.5 M\n","-----------------------------------------------------\n","60.5 M    Trainable params\n","0         Non-trainable params\n","60.5 M    Total params\n","242.026   Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7da568f66ac147fba5e6f4cf5093d6d0","version_minor":0,"version_major":2},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"385fc4f4a1684349b96be1f2a74cef24","version_minor":0,"version_major":2},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8083708fe124deebde2df1f940cecab","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n","  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8d539825f6849b19e013dabd894a101","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9682ed40595b49608658d5d837a9b9e5","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c7530fd401a4e32987a7971070a9e4d","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75fecdcc1276491ea1b25d9df20a0974","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"afb6f64cb7744145bdfac4c470f21df9","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71f0a60bd9484a5f9aced7298e21eabd","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14e18ba82a05401dbeb1b07ac8b4aa5f","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 0 file into the W&B run directory, call wandb.save again to sync new files.\n"]},{"output_type":"stream","name":"stdout","text":["config {'experiment': {'seed': 42, 'data': 'mhqg-wq', 'data_dir': 'data/mhqg-wq/', 'model_name_or_path': 't5-small', 'tokenizer_name_or_path': 't5-small', 'model_dir': 'content/mhqg-wq_t5-small_20210905_1930', 'wandb': {'exp_num': 2, 'project': 'mhqg-wq_t5-small', 'checkpoint_path': 'checkpoint/'}}, 'model': {'max_input_length': 512, 'max_target_length': 100}, 'training': {'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'gradient_accumulation_steps': 1, 'early_stop_callback': True, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42, 'train_batch_size': 2, 'eval_batch_size': 2, 'test_batch_size': 8, 'num_train_epochs': 8, 'precision': 16, 'n_gpu': 1}}\n","type_config <class 'omegaconf.dictconfig.DictConfig'>\n"]},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: None, using: 0 TPU cores\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ba3bee47cc84926846d3495abfb627d","version_minor":0,"version_major":2},"text/plain":["Testing: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","DATALOADER:0 TEST RESULTS\n","{}\n","--------------------------------------------------------------------------------\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 3872<br/>Program ended successfully."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3febc27bfba418b8ae11dec7592c163","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.02MB of 0.02MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Find user logs for this run at: <code>wandb/run-20210905_103540-17fwjt6z/logs/debug.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Find internal logs for this run at: <code>wandb/run-20210905_103540-17fwjt6z/logs/debug-internal.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<h3>Run summary:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>train/loss_step</td><td>1.17318</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>_step</td><td>75951</td></tr><tr><td>_runtime</td><td>11164</td></tr><tr><td>_timestamp</td><td>1630849305</td></tr><tr><td>train/loss_epoch</td><td>0.84061</td></tr><tr><td>valid/loss_epoch</td><td>1.29183</td></tr><tr><td>Bleu_1</td><td>0.50342</td></tr><tr><td>Bleu_2</td><td>0.34667</td></tr><tr><td>Bleu_3</td><td>0.25484</td></tr><tr><td>Bleu_4</td><td>0.19463</td></tr><tr><td>METEOR</td><td>0.24207</td></tr><tr><td>ROUGE_L</td><td>0.46577</td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<h3>Run history:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>train/loss_step</td><td>▆█▅▆▆▃▅▃▅▃▁▂▆▃▃▁▃▄▂▄▃▁▂▂▃▃▁▃▁▁▁▂▂▄▂▂▁▂▂▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/loss_epoch</td><td>█▅▃▃▂▂▁▁</td></tr><tr><td>valid/loss_epoch</td><td>█▄▃▁▁▁▁▁</td></tr><tr><td>Bleu_1</td><td>▁</td></tr><tr><td>Bleu_2</td><td>▁</td></tr><tr><td>Bleu_3</td><td>▁</td></tr><tr><td>Bleu_4</td><td>▁</td></tr><tr><td>METEOR</td><td>▁</td></tr><tr><td>ROUGE_L</td><td>▁</td></tr></table><br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","                    <br/>Synced <strong style=\"color:#cdcd00\">exp_2</strong>: <a href=\"https://wandb.ai/macho000/mhqg-wq_t5-small/runs/17fwjt6z\" target=\"_blank\">https://wandb.ai/macho000/mhqg-wq_t5-small/runs/17fwjt6z</a><br/>\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"aE84GUdLgco0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PpyDE0jvOKgy"},"source":["# t5-small path question"]},{"cell_type":"markdown","metadata":{"id":"98bDYQULOKgz"},"source":["## Install dependency\n","~~~\n","Based on the pyproject.toml in the current path, dependency will be installed in order.\n","~~~"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hXkNxs1oOKgz","executionInfo":{"status":"ok","timestamp":1630849835829,"user_tz":-540,"elapsed":7933,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}},"outputId":"975bac79-ffac-4614-cd35-2c7602d0e07f"},"source":["!pip install -q --pre poetry==1.1.8"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 34.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 35.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 71 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 102 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 112 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 122 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 133 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 143 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 153 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 163 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 173 kB 8.4 MB/s \n","\u001b[K     |████████████████████████████████| 40 kB 7.3 MB/s \n","\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n","\u001b[K     |████████████████████████████████| 5.3 MB 52.0 MB/s \n","\u001b[K     |████████████████████████████████| 91 kB 14.0 MB/s \n","\u001b[K     |████████████████████████████████| 420 kB 86.5 MB/s \n","\u001b[K     |████████████████████████████████| 54 kB 3.4 MB/s \n","\u001b[K     |████████████████████████████████| 3.0 MB 56.3 MB/s \n","\u001b[K     |████████████████████████████████| 338 kB 74.2 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"sEDNbf39OKg0","executionInfo":{"status":"ok","timestamp":1630849977976,"user_tz":-540,"elapsed":142154,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}},"outputId":"85b287cb-3db7-4df6-f58c-02d95c3d1d2e"},"source":["!pip install --requirement <(poetry export --format requirements.txt)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Ignoring colorama: markers 'python_version >= \"3.6\" and python_full_version < \"3.0.0\" and platform_system == \"Windows\" or python_full_version >= \"3.5.0\" and python_version >= \"3.6\" and platform_system == \"Windows\"' don't match your environment\n","Ignoring pywin32: markers 'sys_platform == \"win32\" and python_version >= \"3.6\"' don't match your environment\n","Ignoring waitress: markers 'platform_system == \"Windows\" and python_version >= \"3.6\" and python_full_version >= \"3.6.0\"' don't match your environment\n","Collecting absl-py==0.13.0\n","  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 9.1 MB/s \n","\u001b[?25hCollecting aiohttp==3.7.4.post0\n","  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 84.9 MB/s \n","\u001b[?25hCollecting alembic==1.4.1\n","  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 68.4 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 76.9 MB/s \n","\u001b[?25hCollecting async-timeout==3.0.1\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: attrs==21.2.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 49)) (21.2.0)\n","Requirement already satisfied: cachetools==4.2.2 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 52)) (4.2.2)\n","Requirement already satisfied: certifi==2021.5.30 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 55)) (2021.5.30)\n","Collecting chardet==4.0.0\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[K     |████████████████████████████████| 178 kB 86.1 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer==2.0.4 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 61)) (2.0.4)\n","Collecting click==8.0.1\n","  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 8.5 MB/s \n","\u001b[?25hCollecting cloudpickle==1.6.0\n","  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n","Collecting configparser==5.0.2\n","  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n","Collecting databricks-cli==0.15.0\n","  Downloading databricks-cli-0.15.0.tar.gz (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 5.6 MB/s \n","\u001b[?25hCollecting docker-pycreds==0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting docker==5.0.2\n","  Downloading docker-5.0.2-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 79.6 MB/s \n","\u001b[?25hRequirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 85)) (0.3)\n","Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 88)) (3.0.12)\n","Collecting flask==2.0.1\n","  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.8 MB/s \n","\u001b[?25hCollecting fsspec==2021.8.1\n","  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n","\u001b[K     |████████████████████████████████| 119 kB 72.7 MB/s \n","\u001b[?25hCollecting future==0.18.2\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 70.3 MB/s \n","\u001b[?25hCollecting gitdb==4.0.7\n","  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n","\u001b[?25hCollecting gitpython==3.1.20\n","  Downloading GitPython-3.1.20-py3-none-any.whl (178 kB)\n","\u001b[K     |████████████████████████████████| 178 kB 94.8 MB/s \n","\u001b[?25hCollecting google-auth-oauthlib==0.4.6\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Collecting google-auth==1.35.0\n","  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n","\u001b[K     |████████████████████████████████| 152 kB 70.3 MB/s \n","\u001b[?25hRequirement already satisfied: greenlet==1.1.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 111)) (1.1.1)\n","Requirement already satisfied: grpcio==1.39.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 162)) (1.39.0)\n","Collecting gunicorn==20.1.0\n","  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n","\u001b[?25hCollecting hydra-core==1.1.1\n","  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 80.6 MB/s \n","\u001b[?25hCollecting hydra==2.5\n","  Downloading Hydra-2.5.tar.gz (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 623 kB/s \n","\u001b[?25hCollecting idna==3.2\n","  Downloading idna-3.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 8.2 MB/s \n","\u001b[?25hCollecting importlib-metadata==4.8.1\n","  Downloading importlib_metadata-4.8.1-py3-none-any.whl (17 kB)\n","Requirement already satisfied: importlib-resources==5.2.2 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 228)) (5.2.2)\n","Collecting itsdangerous==2.0.1\n","  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n","Collecting jinja2==3.0.1\n","  Downloading Jinja2-3.0.1-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 89.0 MB/s \n","\u001b[?25hRequirement already satisfied: joblib==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 237)) (1.0.1)\n","Collecting mako==1.1.5\n","  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 5.7 MB/s \n","\u001b[?25hRequirement already satisfied: markdown==3.3.4 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 243)) (3.3.4)\n","Requirement already satisfied: markupsafe==2.0.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 246)) (2.0.1)\n","Collecting mlflow==1.20.2\n","  Downloading mlflow-1.20.2-py3-none-any.whl (14.6 MB)\n","\u001b[K     |████████████████████████████████| 14.6 MB 70.0 MB/s \n","\u001b[?25hCollecting multidict==5.1.0\n","  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n","\u001b[K     |████████████████████████████████| 142 kB 73.4 MB/s \n","\u001b[?25hCollecting nltk==3.6\n","  Downloading nltk-3.6-py3-none-any.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 80.2 MB/s \n","\u001b[?25hCollecting numpy==1.21.1\n","  Downloading numpy-1.21.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[K     |████████████████████████████████| 15.7 MB 135 kB/s \n","\u001b[?25hRequirement already satisfied: oauthlib==3.1.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 374)) (3.1.1)\n","Collecting omegaconf==2.1.1\n","  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 4.4 MB/s \n","\u001b[?25hCollecting packaging==21.0\n","  Downloading packaging-21.0-py3-none-any.whl (40 kB)\n","\u001b[K     |████████████████████████████████| 40 kB 7.4 MB/s \n","\u001b[?25hRequirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 383)) (1.1.5)\n","Collecting pillow==8.3.2\n","  Downloading Pillow-8.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 71.7 MB/s \n","\u001b[?25hRequirement already satisfied: prometheus-client==0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 462)) (0.11.0)\n","Collecting prometheus-flask-exporter==0.18.2\n","  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\n","Requirement already satisfied: promise==2.3 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 467)) (2.3)\n","Requirement already satisfied: protobuf==3.17.3 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 469)) (3.17.3)\n","Collecting psutil==5.8.0\n","  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n","\u001b[K     |████████████████████████████████| 296 kB 91.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 526)) (0.2.8)\n","Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 540)) (0.4.8)\n","Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 554)) (2.4.7)\n","Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 557)) (2.8.2)\n","Collecting python-editor==1.0.4\n","  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n","Collecting pytorch-lightning==1.2.1\n","  Downloading pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n","\u001b[K     |████████████████████████████████| 814 kB 85.2 MB/s \n","\u001b[?25hCollecting pytz==2021.1\n","  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n","\u001b[K     |████████████████████████████████| 510 kB 79.6 MB/s \n","\u001b[?25hCollecting pyyaml==5.3.1\n","  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n","\u001b[K     |████████████████████████████████| 269 kB 85.0 MB/s \n","\u001b[?25hCollecting querystring-parser==1.2.4\n","  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n","Collecting regex==2021.8.28\n","  Downloading regex-2021.8.28-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (745 kB)\n","\u001b[K     |████████████████████████████████| 745 kB 63.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 644)) (1.3.0)\n","Collecting requests==2.26.0\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.0 MB/s \n","\u001b[?25hRequirement already satisfied: rsa==4.7.2 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 651)) (4.7.2)\n","Collecting sacremoses==0.0.45\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 59.6 MB/s \n","\u001b[?25hCollecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 56.5 MB/s \n","\u001b[?25hCollecting sentry-sdk==1.3.1\n","  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 99.8 MB/s \n","\u001b[?25hCollecting shortuuid==1.0.1\n","  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n","Collecting six==1.16.0\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting smmap==4.0.0\n","  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n","Collecting sqlalchemy==1.4.23\n","  Downloading SQLAlchemy-1.4.23-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 54.9 MB/s \n","\u001b[?25hRequirement already satisfied: sqlparse==0.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 743)) (0.4.1)\n","Collecting subprocess32==3.5.4\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 9.0 MB/s \n","\u001b[?25hRequirement already satisfied: tabulate==0.8.9 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 750)) (0.8.9)\n","Requirement already satisfied: tensorboard-data-server==0.6.1 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 753)) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 757)) (1.8.0)\n","Requirement already satisfied: tensorboard==2.6.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 759)) (2.6.0)\n","Collecting torch==1.7.1\n","  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n","\u001b[K     |████████████████████████████████| 776.8 MB 15 kB/s \n","\u001b[?25hCollecting torchtext==0.8.0\n","  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n","\u001b[K     |████████████████████████████████| 6.9 MB 34.7 MB/s \n","\u001b[?25hCollecting torchvision==0.8.2\n","  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n","\u001b[K     |████████████████████████████████| 12.8 MB 17.4 MB/s \n","\u001b[?25hCollecting tqdm==4.62.2\n","  Downloading tqdm-4.62.2-py2.py3-none-any.whl (76 kB)\n","\u001b[K     |████████████████████████████████| 76 kB 5.7 MB/s \n","\u001b[?25hCollecting typing-extensions==3.10.0.2\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Collecting urllib3==1.26.6\n","  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 92.1 MB/s \n","\u001b[?25hCollecting wandb==0.10.7\n","  Downloading wandb-0.10.7-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 86.0 MB/s \n","\u001b[?25hCollecting watchdog==2.1.5\n","  Downloading watchdog-2.1.5-py3-none-manylinux2014_x86_64.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 5.3 MB/s \n","\u001b[?25hCollecting websocket-client==1.2.1\n","  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.9 MB/s \n","\u001b[?25hCollecting werkzeug==2.0.1\n","  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n","\u001b[K     |████████████████████████████████| 288 kB 86.2 MB/s \n","\u001b[?25hCollecting yarl==1.6.3\n","  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 87.0 MB/s \n","\u001b[?25hRequirement already satisfied: zipp==3.5.0 in /usr/local/lib/python3.7/dist-packages (from -r /dev/fd/63 (line 874)) (3.5.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.35.0->-r /dev/fd/63 (line 108)) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.6.0->-r /dev/fd/63 (line 759)) (0.37.0)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'gitpython' candidate (version 3.1.20 at https://files.pythonhosted.org/packages/55/60/f884f01eef2a7255875862ec1b12d57d74113ec6e8d9e16c4d254cd6aa3c/GitPython-3.1.20-py3-none-any.whl#sha256=b1e1c269deab1b08ce65403cf14e10d2ef1f6c89e33ea7c5e5bb0222ea593b8a (from https://pypi.org/simple/gitpython/) (requires-python:>=3.6))\n","Reason for being yanked: Issues with typing of ordered dict\u001b[0m\n","Building wheels for collected packages: alembic, antlr4-python3-runtime, databricks-cli, future, hydra, prometheus-flask-exporter, pyyaml, subprocess32\n","  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158172 sha256=48aedc3c06f113235fb1b1265018f4ac941bf782e8ced182b3fc640fd9651241\n","  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=9acfe48443907cd150391fbe174bdeb5244c17e169add565427c803a078159ff\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for databricks-cli: filename=databricks_cli-0.15.0-py3-none-any.whl size=105260 sha256=6d9a80f0bbcf986696b9794f886bba7540def6737337c0e4a2ec07b9f5e07c7f\n","  Stored in directory: /root/.cache/pip/wheels/e7/ba/75/284f9a90ff7a010bb23b9798f2e9a19dd9fe619379c917bff4\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=f0d9193609f76ff256ad8f3a4ad87da7af6394f55c870cbd08ca31803e2c4fcd\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.5-cp37-cp37m-linux_x86_64.whl size=220769 sha256=1a60813540d095c894700f8db9f5f22fbc8934f29ce7055ac3765296a8fbd1c5\n","  Stored in directory: /root/.cache/pip/wheels/46/28/7d/3b38a41d900da90c4e17576f442bac9344eb1f5a4e78ee9f83\n","  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17415 sha256=881d9c5ab04f158cda914edfe438a5b9cab79cedeab4744e1260675f2642dd13\n","  Stored in directory: /root/.cache/pip/wheels/6a/1e/1c/c765920cb92b2f0343d2dd8b481a407cee2823f9b4bbd2e52a\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44635 sha256=1c9e367aafb829a21b9876e88df42aea558d7254dc16fa12805ce656538d6d22\n","  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=c3f4f23b440c3afe77af62f83ec54cd4dba740a78191b701c93263266e66d224\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","Successfully built alembic antlr4-python3-runtime databricks-cli future hydra prometheus-flask-exporter pyyaml subprocess32\n","Installing collected packages: urllib3, typing-extensions, idna, six, requests, multidict, importlib-metadata, yarl, werkzeug, smmap, jinja2, itsdangerous, google-auth, click, chardet, async-timeout, websocket-client, sqlalchemy, pyyaml, pytz, python-editor, numpy, mako, google-auth-oauthlib, gitdb, fsspec, flask, antlr4-python3-runtime, aiohttp, absl-py, watchdog, tqdm, torch, subprocess32, shortuuid, sentry-sdk, regex, querystring-parser, psutil, prometheus-flask-exporter, pillow, packaging, omegaconf, gunicorn, gitpython, future, docker-pycreds, docker, databricks-cli, configparser, cloudpickle, alembic, wandb, torchvision, torchtext, sentencepiece, sacremoses, pytorch-lightning, nltk, mlflow, hydra-core, hydra\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 3.7.4.3\n","    Uninstalling typing-extensions-3.7.4.3:\n","      Successfully uninstalled typing-extensions-3.7.4.3\n","  Attempting uninstall: idna\n","    Found existing installation: idna 2.10\n","    Uninstalling idna-2.10:\n","      Successfully uninstalled idna-2.10\n","  Attempting uninstall: six\n","    Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 1.7.0\n","    Uninstalling importlib-metadata-1.7.0:\n","      Successfully uninstalled importlib-metadata-1.7.0\n","  Attempting uninstall: werkzeug\n","    Found existing installation: Werkzeug 1.0.1\n","    Uninstalling Werkzeug-1.0.1:\n","      Successfully uninstalled Werkzeug-1.0.1\n","  Attempting uninstall: jinja2\n","    Found existing installation: Jinja2 2.11.3\n","    Uninstalling Jinja2-2.11.3:\n","      Successfully uninstalled Jinja2-2.11.3\n","  Attempting uninstall: itsdangerous\n","    Found existing installation: itsdangerous 1.1.0\n","    Uninstalling itsdangerous-1.1.0:\n","      Successfully uninstalled itsdangerous-1.1.0\n","  Attempting uninstall: google-auth\n","    Found existing installation: google-auth 1.34.0\n","    Uninstalling google-auth-1.34.0:\n","      Successfully uninstalled google-auth-1.34.0\n","  Attempting uninstall: click\n","    Found existing installation: click 7.1.2\n","    Uninstalling click-7.1.2:\n","      Successfully uninstalled click-7.1.2\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 3.0.4\n","    Uninstalling chardet-3.0.4:\n","      Successfully uninstalled chardet-3.0.4\n","  Attempting uninstall: sqlalchemy\n","    Found existing installation: SQLAlchemy 1.4.22\n","    Uninstalling SQLAlchemy-1.4.22:\n","      Successfully uninstalled SQLAlchemy-1.4.22\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pytz\n","    Found existing installation: pytz 2018.9\n","    Uninstalling pytz-2018.9:\n","      Successfully uninstalled pytz-2018.9\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 0.4.5\n","    Uninstalling google-auth-oauthlib-0.4.5:\n","      Successfully uninstalled google-auth-oauthlib-0.4.5\n","  Attempting uninstall: flask\n","    Found existing installation: Flask 1.1.4\n","    Uninstalling Flask-1.1.4:\n","      Successfully uninstalled Flask-1.1.4\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 0.12.0\n","    Uninstalling absl-py-0.12.0:\n","      Successfully uninstalled absl-py-0.12.0\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.62.0\n","    Uninstalling tqdm-4.62.0:\n","      Successfully uninstalled tqdm-4.62.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","  Attempting uninstall: regex\n","    Found existing installation: regex 2019.12.20\n","    Uninstalling regex-2019.12.20:\n","      Successfully uninstalled regex-2019.12.20\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 20.9\n","    Uninstalling packaging-20.9:\n","      Successfully uninstalled packaging-20.9\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.10.0+cu102\n","    Uninstalling torchvision-0.10.0+cu102:\n","      Successfully uninstalled torchvision-0.10.0+cu102\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.10.0\n","    Uninstalling torchtext-0.10.0:\n","      Successfully uninstalled torchtext-0.10.0\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.1 which is incompatible.\n","tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.2 which is incompatible.\n","tensorflow-metadata 1.2.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.13.0 which is incompatible.\n","poetry 1.1.8 requires importlib-metadata<2.0.0,>=1.6.0; python_version < \"3.8\", but you have importlib-metadata 4.8.1 which is incompatible.\n","poetry 1.1.8 requires packaging<21.0,>=20.4, but you have packaging 21.0 which is incompatible.\n","poetry-core 1.0.4 requires importlib-metadata<2.0.0,>=1.7.0; python_version >= \"2.7\" and python_version < \"2.8\" or python_version >= \"3.5\" and python_version < \"3.8\", but you have importlib-metadata 4.8.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed absl-py-0.13.0 aiohttp-3.7.4.post0 alembic-1.4.1 antlr4-python3-runtime-4.8 async-timeout-3.0.1 chardet-4.0.0 click-8.0.1 cloudpickle-1.6.0 configparser-5.0.2 databricks-cli-0.15.0 docker-5.0.2 docker-pycreds-0.4.0 flask-2.0.1 fsspec-2021.8.1 future-0.18.2 gitdb-4.0.7 gitpython-3.1.20 google-auth-1.35.0 google-auth-oauthlib-0.4.6 gunicorn-20.1.0 hydra-2.5 hydra-core-1.1.1 idna-3.2 importlib-metadata-4.8.1 itsdangerous-2.0.1 jinja2-3.0.1 mako-1.1.5 mlflow-1.20.2 multidict-5.1.0 nltk-3.6 numpy-1.21.1 omegaconf-2.1.1 packaging-21.0 pillow-8.3.2 prometheus-flask-exporter-0.18.2 psutil-5.8.0 python-editor-1.0.4 pytorch-lightning-1.2.1 pytz-2021.1 pyyaml-5.3.1 querystring-parser-1.2.4 regex-2021.8.28 requests-2.26.0 sacremoses-0.0.45 sentencepiece-0.1.96 sentry-sdk-1.3.1 shortuuid-1.0.1 six-1.16.0 smmap-4.0.0 sqlalchemy-1.4.23 subprocess32-3.5.4 torch-1.7.1 torchtext-0.8.0 torchvision-0.8.2 tqdm-4.62.2 typing-extensions-3.10.0.2 urllib3-1.26.6 wandb-0.10.7 watchdog-2.1.5 websocket-client-1.2.1 werkzeug-2.0.1 yarl-1.6.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","google","numpy","psutil","pydevd_plugins","pytz","six"]}}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Gu_lrZHUOKg1"},"source":["## Import Library"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"id":"Z9pwnhGbOKg1","executionInfo":{"status":"ok","timestamp":1630850063665,"user_tz":-540,"elapsed":60467,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}},"outputId":"56babe0e-4003-4a66-e686-86190a64b359"},"source":["import argparse\n","import glob\n","import os\n","import json\n","import time\n","import logging\n","import random\n","import re\n","from itertools import chain\n","from string import punctuation\n"," \n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import pytorch_lightning as pl\n","\n","import io\n","import string\n","from collections import Counter, defaultdict, OrderedDict\n","from nltk.tokenize import wordpunct_tokenize, word_tokenize\n"," \n","import gc\n","\n","from AdjacencyAttentionWithoutSelfloopTransformers import (\n","  AdamW,\n","  T5ForConditionalGeneration,\n","  T5Tokenizer,\n","  get_linear_schedule_with_warmup\n",")\n","\n","import os.path\n","\n","import wandb\n","wandb.login()"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"]},{"name":"stdout","output_type":"stream","text":["wandb: Paste an API key from your profile and hit enter: ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"4PeZfxefOKg1"},"source":["## Preprocess"]},{"cell_type":"code","metadata":{"id":"hYReW4bVOKg1","executionInfo":{"status":"ok","timestamp":1630850065302,"user_tz":-540,"elapsed":1654,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}}},"source":["def preprocess_wq(config):\n","    if not os.path.isfile(\"processed/mhqg-wq/SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-wq/SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-wq/SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-wq/TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-wq/TARGET_MASK_memmap.npy\"\n","        # input_length = 18624\n","        input_length = 18989\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-wq/train.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","                n = len(jo['inGraph']['g_node_names'])\n","                adj_matrix = {}\n","                adj_matrix2 = {}\n","                graph = {'node_name_id2word':{}}\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        edge = edge.split('/')[-1]\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1\n","\n","    if not os.path.isfile(\"processed/mhqg-wq/VAL_SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-wq/VAL_SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-wq/VAL_SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/VAL_SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-wq/VAL_TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-wq/VAL_TARGET_MASK_memmap.npy\"\n","        # input_length = 18624\n","        input_length = 2000\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-wq/dev.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","                n = len(jo['inGraph']['g_node_names'])\n","                adj_matrix = {}\n","                adj_matrix2 = {}\n","                graph = {'node_name_id2word':{}}\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        edge = edge.split('/')[-1]\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1\n","\n","    if not os.path.isfile(\"processed/mhqg-wq/TEST_SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-wq/TEST_SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-wq/TEST_SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/TEST_SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-wq/TEST_TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-wq/TEST_TARGET_MASK_memmap.npy\"\n","        # input_length = 18624\n","        input_length = 2000\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-wq/test.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","                n = len(jo['inGraph']['g_node_names'])\n","                adj_matrix = {}\n","                adj_matrix2 = {}\n","                graph = {'node_name_id2word':{}}\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        edge = edge.split('/')[-1]\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"LT5sUpPAOKg5","executionInfo":{"status":"ok","timestamp":1630850066727,"user_tz":-540,"elapsed":1428,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}}},"source":["def preprocess_pq(config):\n","    # preprocess input data\n","    if not os.path.isfile(\"processed/mhqg-pq/SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-pq/SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-pq/SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-pq/TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-pq/TARGET_MASK_memmap.npy\"\n","        input_length = 9793\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-pq/train.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","\n","                # used for model input\n","                adj_matrix = {}\n","                # used for create adjacency matrix\n","                adj_matrix2 = {}\n","                # map from id to node name\n","                graph = {'node_name_id2word':{}}\n","\n","                # make graph mapping from id to node name\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","\n","\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1\n","\n","    # preprocess validation.json \n","    if not os.path.isfile(\"processed/mhqg-pq/VAL_SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-pq/VAL_SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-pq/VAL_SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/VAL_SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-pq/VAL_TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-pq/VAL_TARGET_MASK_memmap.npy\"\n","        input_length = 1000\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-pq/dev.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","\n","                # used for model input\n","                adj_matrix = {}\n","                # used for create adjacency matrix\n","                adj_matrix2 = {}\n","                # map from id to node name\n","                graph = {'node_name_id2word':{}}\n","\n","                # make graph mapping from id to node name\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","\n","\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1\n","\n","    # preprocess test.json\n","    if not os.path.isfile(\"processed/mhqg-pq/TEST_SOURCE_ID_memmap.npy\"):\n","        SOURCE_ID_PATH = \"processed/mhqg-pq/TEST_SOURCE_ID_memmap.npy\"\n","        SOURCE_MASK_PATH = \"processed/mhqg-pq/TEST_SOURCE_MASK_memmap.npy\"\n","        SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/TEST_SOURCE_CROSS_MASK_memmap.npy\"\n","        TARGET_ID_PATH = \"processed/mhqg-pq/TEST_TARGET_ID_memmap.npy\"\n","        TARGET_MASK_PATH = \"processed/mhqg-pq/TEST_TARGET_MASK_memmap.npy\"\n","        # input_length = 18624\n","        input_length = 1000\n","        SOURCE_ID_memmap = np.memmap(\n","        filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,512) \n","        )\n","\n","        SOURCE_MASK_memmap = np.memmap(\n","        filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512,512)\n","        )\n","\n","        SOURCE_CROSS_MASK_memmap = np.memmap(\n","        filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,512)\n","        )\n","\n","        TARGET_ID_memmap = np.memmap(\n","        filename=TARGET_ID_PATH, dtype=np.int64, mode=\"w+\", shape=(input_length,100)\n","        )\n","\n","        TARGET_MASK_memmap = np.memmap(\n","        filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"w+\",shape=(input_length,100)\n","        )\n","\n","        del SOURCE_ID_memmap\n","        del SOURCE_MASK_memmap\n","        del SOURCE_CROSS_MASK_memmap\n","        del TARGET_ID_memmap\n","        del TARGET_MASK_memmap\n","        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        with open(\"data/mhqg-pq/test.json\", 'r') as f:\n","            list_index = 0\n","            for index, line in enumerate(f):\n","                line = line.strip()\n","                jo = json.loads(line, object_pairs_hook=OrderedDict)\n","                assert len(jo['inGraph']['g_adj']) > 0\n","\n","                answers = jo['answers']\n","                normalized_answers = \"\"\n","                for x in answers:\n","                    normalized_answers += (x + \" \")\n","                target = jo['outSeq']\n","\n","                # used for model input\n","                adj_matrix = {}\n","                # used for create adjacency matrix\n","                adj_matrix2 = {}\n","                # map from id to node name\n","                graph = {'node_name_id2word':{}}\n","\n","                # make graph mapping from id to node name\n","                for idx, nid in enumerate(jo['inGraph']['g_node_names']):\n","                    # replace answer token to \"<answer> answer <answer>\"\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        graph['node_name_id2word'][nid] = \"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"\n","                    else:\n","                        graph['node_name_id2word'][nid] = jo['inGraph']['g_node_names'][nid]\n","\n","                    # create adj_matrix with 0 value\n","                    for idy, nid2 in enumerate(jo['inGraph']['g_node_names']):\n","                        if jo['inGraph']['g_node_names'][nid2] in answers:\n","                            adj_matrix2[\"<answer> \"+ jo['inGraph']['g_node_names'][nid2] + \" <answer>\"] = 0\n","                        else:\n","                            adj_matrix2[jo['inGraph']['g_node_names'][nid2]] = 0\n","\n","                    if jo['inGraph']['g_node_names'][nid] in answers:\n","                        adj_matrix[\"<answer> \"+ jo['inGraph']['g_node_names'][nid] + \" <answer>\"] = adj_matrix2.copy()\n","                    else:\n","                        adj_matrix[jo['inGraph']['g_node_names'][nid]] = adj_matrix2.copy()\n","\n","\n","                for nid, val in jo['inGraph']['g_adj'].items():\n","                    for nid2, edge in val.items():\n","                        adj_matrix[graph[\"node_name_id2word\"][nid]][graph[\"node_name_id2word\"][nid2]] = 1\n","                input_knowledge_graph = \"\"\n","                for i,ids in enumerate(list(adj_matrix.keys())):\n","                    input_knowledge_graph += (ids + \" \")\n","\n","                input, target = input_knowledge_graph, target\n","\n","                tokenized_row_input = \"\"\n","                tokenized_row_input = tokenizer.tokenize(input)\n","                if len(tokenized_row_input) > 512:\n","                    continue\n","\n","                tokenized_inputs = tokenizer.batch_encode_plus_self_attention(\n","                    [input_knowledge_graph], adjacancy_matrix=adj_matrix, max_length=512, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","\n","                tokenized_targets = tokenizer.batch_encode_plus(\n","                    [target], max_length=100, truncation=True, \n","                    padding=\"max_length\", return_tensors=\"pt\"\n","                )\n","                SOURCE_ID_memmap = np.memmap(\n","                    filename=SOURCE_ID_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,512) \n","                )\n","\n","                SOURCE_MASK_memmap = np.memmap(\n","                    filename=SOURCE_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512,512)\n","                )\n","\n","                SOURCE_CROSS_ATTENTION_MASK_memmap = np.memmap(\n","                    filename=SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,512)\n","                )\n","\n","                TARGET_ID_memmap = np.memmap(\n","                    filename=TARGET_ID_PATH, dtype=np.int64, mode=\"r+\", shape=(input_length,100)\n","                )\n","\n","                TARGET_MASK_memmap = np.memmap(\n","                    filename=TARGET_MASK_PATH, dtype=np.int64, mode=\"r+\",shape=(input_length,100)\n","                )\n","\n","                SOURCE_ID_memmap[list_index] = tokenized_inputs[\"input_ids\"].squeeze().numpy()\n","                SOURCE_MASK_memmap[list_index] = tokenized_inputs[\"attention_mask\"].squeeze().numpy()\n","                SOURCE_CROSS_ATTENTION_MASK_memmap[list_index] = tokenized_inputs[\"cross_attention_mask\"].squeeze().numpy()\n","\n","                TARGET_ID_memmap[list_index] = tokenized_targets[\"input_ids\"].squeeze().numpy()\n","                TARGET_MASK_memmap[list_index] = tokenized_targets[\"attention_mask\"].squeeze().numpy()\n","\n","                del SOURCE_ID_memmap\n","                del SOURCE_MASK_memmap\n","                del SOURCE_CROSS_ATTENTION_MASK_memmap\n","                del TARGET_ID_memmap\n","                del TARGET_MASK_memmap\n","\n","                if index%500==0:\n","                    print(f\"{index} was finished\", index)\n","\n","                list_index += 1"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"07GrrtPSOKg8","executionInfo":{"status":"ok","timestamp":1630850066728,"user_tz":-540,"elapsed":8,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}}},"source":["class Preprocess():\n","    def __init__(self, config):\n","        if config.experiment.data==\"mhqg-wq\":\n","            preprocess_wq(config)\n","        elif config.experiment.data==\"mhqg-pq\":\n","            preprocess_pq(config)\n","        else:\n","            raise"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ONU0dk4wOKg8"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"uq4AcrkiOKg8","executionInfo":{"status":"ok","timestamp":1630850066729,"user_tz":-540,"elapsed":8,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}}},"source":["from torch.utils.data import Dataset\n","import numpy as np\n","import json\n","import torch\n","from collections import Counter, defaultdict, OrderedDict\n","import gc\n","import os\n","\n","class JsonDatasetWQ(Dataset):\n","    def __init__(self, tokenizer, data_dir, type_path, input_max_len=512, target_max_len=512, mode=None):\n","        assert mode==\"Train\" or mode==\"Val\" or mode==\"Test\"\n","        self.file_path = os.path.join(data_dir, type_path)\n","        \n","        self.input_max_len = input_max_len\n","        self.target_max_len = target_max_len\n","        self.tokenizer = tokenizer\n","        self.inputs = []\n","        self.targets = []\n"," \n","        self.mode = mode\n"," \n","        if mode==\"Train\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-wq/SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-wq/SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-wq/TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-wq/TARGET_MASK_memmap.npy\"\n","        #   self.input_length = 18624\n","          self.input_length = 18989\n","          self.list_index = 18989\n","        elif mode==\"Val\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-wq/VAL_SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-wq/VAL_SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/VAL_SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-wq/VAL_TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-wq/VAL_TARGET_MASK_memmap.npy\"\n","          self.input_length = 2000\n","          self.list_index = 2000\n","        #   self.input_length = 1985\n","        elif mode==\"Test\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-wq/TEST_SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-wq/TEST_SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-wq/TEST_SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-wq/TEST_TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-wq/TEST_TARGET_MASK_memmap.npy\"\n","          self.input_length = 2000\n","          self.list_index = 2000\n","          \n","        #   self.input_length = 1985\n"," \n","        self.SOURCE_ID_memmap = np.memmap(\n","          filename=self.SOURCE_ID_PATH, dtype=np.int64, mode=\"r\",shape=(self.input_length,512) \n","        )\n"," \n","        self.SOURCE_MASK_memmap = np.memmap(\n","          filename=self.SOURCE_MASK_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,512,512)\n","        )\n","\n","        self.VAL_SOURCE_CROSS_MASK_memmap = np.memmap(\n","          filename=self.SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,512)\n","        )\n"," \n","        self.TARGET_ID_memmap = np.memmap(\n","          filename=self.TARGET_ID_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,100)\n","        )\n"," \n","        self.TARGET_MASK_memmap = np.memmap(\n","          filename=self.TARGET_MASK_PATH, dtype=np.int64, mode=\"r\",shape=(self.input_length,100)\n","        )\n","\n","  \n","    def __len__(self):\n","        return self.list_index\n","  \n","    def __getitem__(self, index):\n","        return {\"source_ids\": torch.from_numpy(np.array(self.SOURCE_ID_memmap[index])).squeeze(), \"source_mask\": torch.from_numpy(np.array(self.SOURCE_MASK_memmap[index])).squeeze(), \"cross_attention_mask\":torch.from_numpy(np.array(self.VAL_SOURCE_CROSS_MASK_memmap[index])).squeeze(),\n","                \"target_ids\": torch.from_numpy(np.array(self.TARGET_ID_memmap[index])).squeeze(), \"target_mask\": torch.from_numpy(np.array(self.TARGET_MASK_memmap[index])).squeeze()}"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"B1QP0frdOKg8","executionInfo":{"status":"ok","timestamp":1630850066729,"user_tz":-540,"elapsed":8,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}}},"source":["from torch.utils.data import Dataset\n","import numpy as np\n","import json\n","import torch\n","from collections import Counter, defaultdict, OrderedDict\n","import gc\n","import os\n","\n","class JsonDatasetPQ(Dataset):\n","    def __init__(self, tokenizer, data_dir, type_path, input_max_len=512, target_max_len=512, mode=None):\n","        assert mode==\"Train\" or mode==\"Val\" or mode==\"Test\"\n","        self.file_path = os.path.join(data_dir, type_path)\n","        \n","        self.input_max_len = input_max_len\n","        self.target_max_len = target_max_len\n","        self.tokenizer = tokenizer\n","        self.inputs = []\n","        self.targets = []\n"," \n","        self.mode = mode\n"," \n","        if mode==\"Train\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-pq/SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-pq/SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-pq/TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-pq/TARGET_MASK_memmap.npy\"\n","          self.input_length = 9793\n","          self.list_index = 9793\n","        elif mode==\"Val\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-pq/VAL_SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-pq/VAL_SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/VAL_SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-pq/VAL_TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-pq/VAL_TARGET_MASK_memmap.npy\"\n","          self.input_length = 1000\n","          self.list_index = 1000\n","        elif mode==\"Test\":\n","          self.SOURCE_ID_PATH = \"processed/mhqg-pq/TEST_SOURCE_ID_memmap.npy\"\n","          self.SOURCE_MASK_PATH = \"processed/mhqg-pq/TEST_SOURCE_MASK_memmap.npy\"\n","          self.SOURCE_CROSS_MASK_PATH = \"processed/mhqg-pq/TEST_SOURCE_CROSS_MASK_memmap.npy\"\n","          self.TARGET_ID_PATH = \"processed/mhqg-pq/TEST_TARGET_ID_memmap.npy\"\n","          self.TARGET_MASK_PATH = \"processed/mhqg-pq/TEST_TARGET_MASK_memmap.npy\"\n","          self.input_length = 1000\n","          self.list_index = 1000\n","          \n"," \n","        self.SOURCE_ID_memmap = np.memmap(\n","          filename=self.SOURCE_ID_PATH, dtype=np.int64, mode=\"r\",shape=(self.input_length,512) \n","        )\n"," \n","        self.SOURCE_MASK_memmap = np.memmap(\n","          filename=self.SOURCE_MASK_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,512,512)\n","        )\n","\n","        self.VAL_SOURCE_CROSS_MASK_memmap = np.memmap(\n","          filename=self.SOURCE_CROSS_MASK_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,512)\n","        )\n"," \n","        self.TARGET_ID_memmap = np.memmap(\n","          filename=self.TARGET_ID_PATH, dtype=np.int64, mode=\"r\", shape=(self.input_length,100)\n","        )\n"," \n","        self.TARGET_MASK_memmap = np.memmap(\n","          filename=self.TARGET_MASK_PATH, dtype=np.int64, mode=\"r\",shape=(self.input_length,100)\n","        )\n","\n","  \n","    def __len__(self):\n","        return self.list_index\n","  \n","    def __getitem__(self, index):\n","        return {\"source_ids\": torch.from_numpy(np.array(self.SOURCE_ID_memmap[index])).squeeze(), \"source_mask\": torch.from_numpy(np.array(self.SOURCE_MASK_memmap[index])).squeeze(), \"cross_attention_mask\":torch.from_numpy(np.array(self.VAL_SOURCE_CROSS_MASK_memmap[index])).squeeze(),\n","                \"target_ids\": torch.from_numpy(np.array(self.TARGET_ID_memmap[index])).squeeze(), \"target_mask\": torch.from_numpy(np.array(self.TARGET_MASK_memmap[index])).squeeze()}"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rD3vYjGBOKg9"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"gBuL4bL8OKg9","executionInfo":{"status":"ok","timestamp":1630850071282,"user_tz":-540,"elapsed":4560,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}}},"source":["import pytorch_lightning as pl\n","from AdjacencyAttentionWithoutSelfloopTransformers import (\n","  AdamW,\n","  T5ForConditionalGeneration,\n","  T5Tokenizer,\n","  get_linear_schedule_with_warmup\n",")\n","from torch.utils.data import DataLoader\n","\n","from tqdm.auto import tqdm\n","\n","import pandas as pd\n","from core.evaluation.eval import QGEvalCap\n","\n","from omegaconf import DictConfig\n","\n","def saveOutputs(hparams: DictConfig, inputs: list, outputs: list, targets: list) -> None:\n","  data = pd.DataFrame(list(zip(inputs, outputs, targets)), columns =['inputs', 'outputs', 'targets'])\n","  data.to_csv(os.path.join(\"out\",hparams.experiment.model_dir.split(\"/\")[-1]+\".csv\"),index=False, header=True)\n","\n","def run_eval(target_src, decoded_text) -> dict:\n","  assert len(target_src) == len(decoded_text)\n","  eval_targets = {}\n","  eval_predictions = {}\n","  for idx in range(len(target_src)):\n","      eval_targets[idx] = [target_src[idx]]\n","      eval_predictions[idx] = [decoded_text[idx]]\n","\n","  QGEval = QGEvalCap(eval_targets, eval_predictions)\n","  scores = QGEval.evaluate()\n","  return scores\n","\n","class T5FineTuner(pl.LightningModule):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        # 事前学習済みモデルの読み込み\n","        self.model = T5ForConditionalGeneration.from_pretrained(config.experiment.model_name_or_path)\n","\n","        # トークナイザーの読み込み\n","        self.tokenizer = T5Tokenizer.from_pretrained(config.experiment.tokenizer_name_or_path, is_fast=True)\n","\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        self.save_hyperparameters()\n","\n","    def forward(self, input_ids, attention_mask=None, cross_attention_mask=None, decoder_input_ids=None, \n","                decoder_attention_mask=None, labels=None, mode=None):\n","        \"\"\"順伝搬\"\"\"\n","        return self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            cross_attention_mask=cross_attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","            labels=labels,\n","            three_dim_attention_mask=True\n","        )\n","\n","    def _step(self, batch, mode=None):\n","        \"\"\"ロス計算\"\"\"\n","        labels = batch[\"target_ids\"].detach().clone()\n","\n","        # All labels set to -100 are ignored (masked), \n","        # the loss is only computed for labels in [0, ..., config.vocab_size]\n","        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n","\n","        outputs = self(\n","            input_ids=batch[\"source_ids\"],\n","            attention_mask=batch[\"source_mask\"],\n","            cross_attention_mask=batch[\"cross_attention_mask\"],\n","            decoder_attention_mask=batch['target_mask'],\n","            labels=labels,\n","            mode=mode\n","        )\n","\n","        return outputs\n","\n","    def training_step(self, batch, batch_idx):\n","        \"\"\"訓練ステップ処理\"\"\"\n","        outputs = self._step(batch)\n","        loss = outputs[0]\n","        logit = outputs[1]\n","        # logging metrics we calculated by hand\n","        self.log('train/loss', loss, on_epoch=True)\n","        return {\"loss\": loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","        \"\"\"バリデーションステップ処理\"\"\"\n","        outputs = self._step(batch)\n","        loss = outputs[0]\n","        logit = outputs[1]\n","        self.log(\"valid/loss_epoch\", loss)  # default on val/test is on_epoch only\n","        return {\"val_loss\": loss}\n","\n","    def test_epoch_end(self, training_step_outputs):\n","        saveOutputs(self.config, self.inputs, self.outputs, self.targets)\n","        scores = run_eval(self.targets, self.outputs)\n","        wandb.log(scores)\n","\n","    def configure_optimizers(self):\n","        \"\"\"オプティマイザーとスケジューラーを作成する\"\"\"\n","        model = self.model\n","        no_decay = [\"bias\", \"LayerNorm.weight\"]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [p for n, p in model.named_parameters() \n","                            if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": self.config.training.weight_decay,\n","            },\n","            {\n","                \"params\": [p for n, p in model.named_parameters() \n","                            if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters, \n","                          lr=self.config.training.learning_rate, \n","                          eps=self.config.training.adam_epsilon)\n","        self.optimizer = optimizer\n","\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=self.config.training.warmup_steps, \n","            num_training_steps=self.t_total\n","        )\n","        self.scheduler = scheduler\n","\n","        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}]\n","\n","    def get_dataset(self, tokenizer, type_path, args, mode=None):\n","        \"\"\"データセットを作成する\"\"\"\n","        if args.experiment.data==\"mhqg-wq\":\n","          return JsonDatasetWQ(\n","            tokenizer=tokenizer, \n","            data_dir=args.experiment.data_dir, \n","            type_path=type_path, \n","            input_max_len=args.model.max_input_length,\n","            target_max_len=args.model.max_target_length,\n","            mode=mode)\n","        else:\n","          return JsonDatasetPQ(\n","            tokenizer=tokenizer, \n","            data_dir=args.experiment.data_dir, \n","            type_path=type_path, \n","            input_max_len=args.model.max_input_length,\n","            target_max_len=args.model.max_target_length,\n","            mode=mode)\n","    \n","    def setup(self, stage=None):\n","        \"\"\"初期設定（データセットの読み込み）\"\"\"\n","        if stage == 'fit' or stage is None:\n","            train_dataset = self.get_dataset(tokenizer=self.tokenizer, \n","                                             type_path=\"train.json\", args=self.config, mode=\"Train\")\n","            self.train_dataset = train_dataset\n","\n","            val_dataset = self.get_dataset(tokenizer=self.tokenizer, \n","                                           type_path=\"dev.json\", args=self.config, mode=\"Val\")\n","            self.val_dataset = val_dataset\n","\n","            self.t_total = (\n","                (len(train_dataset) // (self.config.training.train_batch_size * max(1, self.config.training.n_gpu)))\n","                // self.config.training.gradient_accumulation_steps\n","                * float(self.config.training.num_train_epochs)\n","            )\n","        elif stage == 'test':\n","            val_dataset = self.get_dataset(tokenizer=self.tokenizer, \n","                                           type_path=\"test.json\", args=self.config, mode=\"Test\")\n","            self.test_dataset = test_dataset\n","\n","    def train_dataloader(self):\n","        \"\"\"訓練データローダーを作成する\"\"\"\n","        return DataLoader(self.train_dataset, \n","                          batch_size=self.config.training.train_batch_size, \n","                          drop_last=True, shuffle=True, num_workers=4)\n","\n","    def val_dataloader(self):\n","        \"\"\"バリデーションデータローダーを作成する\"\"\"\n","        return DataLoader(self.val_dataset, \n","                          batch_size=self.config.training.eval_batch_size, \n","                          num_workers=4)\n","        \n","    def test_dataloader(self):\n","        \"\"\"バリデーションデータローダーを作成する\"\"\"\n","        return DataLoader(self.val_dataset, \n","                          batch_size=self.config.training.test_batch_size, \n","                          num_workers=4)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TfaHe-bCOKg9"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"QJ5Xfad1OKg-","executionInfo":{"status":"ok","timestamp":1630850071286,"user_tz":-540,"elapsed":8,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}}},"source":["from AdjacencyAttentionWithoutSelfloopTransformers import (\n","  AdamW,\n","  T5ForConditionalGeneration,\n","  T5Tokenizer,\n","  get_linear_schedule_with_warmup\n",")\n","from torch.utils.data import DataLoader\n","\n","from tqdm.auto import tqdm\n","\n","import pandas as pd\n","from core.evaluation.eval import QGEvalCap\n","\n","from omegaconf import DictConfig\n","\n","\n","# OmegaConf.register_new_resolver(\"now\", lambda pattern: strftime(pattern, localtime()))\n","\n","def saveOutputs(hparams: DictConfig, inputs: list, outputs: list, targets: list) -> None:\n","  data = pd.DataFrame(list(zip(inputs, outputs, targets)), columns =['inputs', 'outputs', 'targets'])\n","  data.to_csv(os.path.join(\"out\",hparams.experiment.model_dir.split(\"/\")[-1]+\".csv\"),index=False, header=True)\n","\n","def run_eval(target_src, decoded_text) -> dict:\n","  assert len(target_src) == len(decoded_text)\n","  eval_targets = {}\n","  eval_predictions = {}\n","  for idx in range(len(target_src)):\n","      eval_targets[idx] = [target_src[idx]]\n","      eval_predictions[idx] = [decoded_text[idx]]\n","\n","  QGEval = QGEvalCap(eval_targets, eval_predictions)\n","  scores = QGEval.evaluate()\n","  return scores\n","\n","class T5Evaluation(pl.LightningModule):\n","    def __init__(self, config: DictConfig, train_params: DictConfig):\n","        super().__init__()\n","        self.config = config\n","        self.train_params = train_params\n","        # 事前学習済みモデルの読み込み\n","        self.model = T5ForConditionalGeneration.from_pretrained(self.config.experiment.model_dir)\n","\n","        # トークナイザーの読み込み\n","        self.tokenizer = T5Tokenizer.from_pretrained(self.config.experiment.model_dir, is_fast=True)\n","        special_tokens_dict = {'sep_token': '<sep>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<answer>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<SEP>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<subject>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<relation>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        special_tokens_dict = {'sep_token': '<object>'}\n","        self.tokenizer.add_special_tokens(special_tokens_dict)\n","\n","        self.save_hyperparameters()\n","\n","        self.inputs = []\n","        self.outputs = []\n","        self.targets = []\n","\n","\n","    def forward(self, input_ids, attention_mask=None, cross_attention_mask=None, decoder_input_ids=None, \n","                decoder_attention_mask=None, labels=None):\n","        \"\"\"順伝搬\"\"\"\n","        return self.model.generate(input_ids=input_ids, \n","            attention_mask=attention_mask, \n","            cross_attention_mask=cross_attention_mask,\n","            max_length=self.config.model.max_target_length,\n","            temperature=1.0,          # 生成にランダム性を入れる温度パラメータ\n","            repetition_penalty=1.5,   # 同じ文の繰り返し（モード崩壊）へのペナルティ\n","            three_dim_attention_mask=True\n","            )\n","\n","    def _step(self, batch):\n","        \"\"\"ロス計算\"\"\"\n","        labels = batch[\"target_ids\"]\n","\n","        # All labels set to -100 are ignored (masked), \n","        # the loss is only computed for labels in [0, ..., config.vocab_size]\n","        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n","\n","        outputs = self(\n","            input_ids=batch[\"source_ids\"],\n","            attention_mask=batch[\"source_mask\"],\n","            cross_attention_mask=batch[\"cross_attention_mask\"],\n","            decoder_attention_mask=batch['target_mask'],\n","            labels=labels\n","        )\n","\n","        return outputs\n","\n","    def test_step(self, batch, batch_idx):\n","        \"\"\"テストステップ処理\"\"\"\n","        output = self._step(batch)\n","        labels = batch[\"target_ids\"]\n","        labels[labels[:, :] == -100] = 0\n","        output_text = [self.tokenizer.decode(ids, skip_special_tokens=True, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in output]\n","        target_text = [self.tokenizer.decode(ids, skip_special_tokens=True, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in labels]\n","        input_text = [self.tokenizer.decode(ids, skip_special_tokens=False, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in batch[\"source_ids\"]]\n","\n","        self.inputs.extend(input_text)\n","        self.outputs.extend(output_text)\n","        self.targets.extend(target_text)\n","\n","        return {\"batch_idx\":batch_idx}\n","        \n","    \n","    def test_epoch_end(self, training_step_outputs):\n","        saveOutputs(self.config, self.inputs, self.outputs, self.targets)\n","        scores = run_eval(self.targets, self.outputs)\n","        wandb.log(scores)\n","\n","    def configure_optimizers(self):\n","        \"\"\"オプティマイザーとスケジューラーを作成する\"\"\"\n","        model = self.model\n","        no_decay = [\"bias\", \"LayerNorm.weight\"]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [p for n, p in model.named_parameters() \n","                            if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": self.config.training.weight_decay,\n","            },\n","            {\n","                \"params\": [p for n, p in model.named_parameters() \n","                            if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters, \n","                          lr=self.config.training.learning_rate, \n","                          eps=self.config.training.adam_epsilon)\n","        self.optimizer = optimizer\n","\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=self.config.training.warmup_steps, \n","            num_training_steps=self.t_total\n","        )\n","        self.scheduler = scheduler\n","\n","        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}]\n","\n","    def get_dataset(self, tokenizer, type_path, mode=None):\n","        \"\"\"データセットを作成する\"\"\"\n","        if self.config.get('experiment').data==\"mhqg-wq\":\n","          return JsonDatasetWQ(\n","            tokenizer=tokenizer, \n","            data_dir=self.config.experiment.data_dir, \n","            type_path=type_path, \n","            input_max_len=self.config.model.max_input_length,\n","            target_max_len=self.config.model.max_target_length,\n","            mode=mode)\n","        else:\n","          return JsonDatasetPQ(\n","            tokenizer=tokenizer, \n","            data_dir=self.config.experiment.data_dir, \n","            type_path=type_path, \n","            input_max_len=self.config.model.max_input_length,\n","            target_max_len=self.config.model.max_target_length,\n","            mode=mode)\n","    \n","    def setup(self, stage=None):\n","        \"\"\"初期設定（データセットの読み込み）\"\"\"\n","        if stage == 'test':\n","            test_dataset = self.get_dataset(tokenizer=self.tokenizer, \n","                                           type_path=\"test.json\", mode=\"Test\")\n","            self.test_dataset = test_dataset\n","        \n","    def test_dataloader(self):\n","        \"\"\"バリデーションデータローダーを作成する\"\"\"\n","        return DataLoader(self.test_dataset, \n","                          batch_size=self.config.training.test_batch_size, \n","                          num_workers=4)\n","\n","class Evaluation():\n","  def __init__(self, config, train_params):\n","    self.config = config\n","    self.train_params = train_params\n","\n","  def run(self):\n","    # Tokenizer\n","    tokenizer = T5Tokenizer.from_pretrained(self.config.experiment.model_dir, is_fast=True)\n","    trained_model = T5ForConditionalGeneration.from_pretrained(self.config.experiment.model_dir)\n","\n","    if self.config.experiment.data==\"mhqg-wq\":\n","        # import test data\n","        test_dataset = JsonDatasetWQ(tokenizer, self.config.experiment.data_dir, \"test.json\", \n","                                input_max_len=self.config.model.max_input_length, \n","                                target_max_len=self.config.model.max_target_length,\n","                                mode=\"Test\")\n","\n","    test_loader = DataLoader(test_dataset, batch_size=8, num_workers=4)\n","\n","    trained_model.eval()\n","\n","    inputs = []\n","    outputs = []\n","    targets = []\n","\n","    for index, batch in enumerate(tqdm(test_loader)):\n","        input_ids = batch['source_ids']\n","        input_mask = batch['source_mask']\n","        input_cross_attention_mask = batch[\"cross_attention_mask\"]\n","        if self.config.training.n_gpu:\n","            input_ids = input_ids.cuda()\n","            input_mask = input_mask.cuda()\n","\n","        output = trained_model.generate(input_ids=input_ids, \n","            attention_mask=input_mask, \n","            cross_attention_mask=input_cross_attention_mask,\n","            max_length=self.config.model.max_target_length,\n","            temperature=1.0,          # 生成にランダム性を入れる温度パラメータ\n","            repetition_penalty=1.5,   # 同じ文の繰り返し（モード崩壊）へのペナルティ\n","            three_dim_attention_mask=True\n","            )\n","\n","        output_text = [tokenizer.decode(ids, skip_special_tokens=True, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in output]\n","        target_text = [tokenizer.decode(ids, skip_special_tokens=True, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in batch[\"target_ids\"]]\n","        input_text = [tokenizer.decode(ids, skip_special_tokens=False, \n","                                clean_up_tokenization_spaces=False) \n","                    for ids in input_ids]\n","\n","        inputs.extend(input_text)\n","        outputs.extend(output_text)\n","        targets.extend(target_text)\n","\n","        saveOutputs(self.config, inputs, outputs, targets)\n","        scores = run_eval(targets, outputs)\n","        self.train_params[\"logger\"].log_metrics(scores)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"udVW9PKyOKg-"},"source":["## Main"]},{"cell_type":"code","metadata":{"id":"IJLFpL4tOKg-","executionInfo":{"status":"ok","timestamp":1630850071635,"user_tz":-540,"elapsed":5,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}}},"source":["import argparse\n","import glob\n","import os\n","import json\n","import time\n","import logging\n","import random\n","from itertools import chain\n","from string import punctuation\n"," \n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","from collections import Counter, defaultdict, OrderedDict\n","from nltk.tokenize import wordpunct_tokenize, word_tokenize\n"," \n","import gc\n","\n","from omegaconf import DictConfig\n","import omegaconf\n","\n","import hydra\n","import pytorch_lightning as pl\n","\n","\n","\n","import textwrap\n","from tqdm.auto import tqdm\n","from sklearn import metrics\n","\n","from pytorch_lightning.loggers import WandbLogger\n","\n","\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n","def get_train_param(config: DictConfig) -> dict:\n","    wandb_logger = WandbLogger(\n","        name=(\"exp_\" + str(config.experiment.wandb.exp_num)),\n","        project=config.experiment.wandb.project,\n","        log_model=True,\n","    )\n","    checkpoint_path = os.path.join(\n","        config.experiment.model_dir, config.experiment.wandb.checkpoint_path\n","    )\n","    wandb_logger.log_hyperparams(config)\n","    train_params = dict(\n","        logger = wandb_logger,\n","        accumulate_grad_batches=config.training.gradient_accumulation_steps,\n","        gpus=config.training.n_gpu,\n","        max_epochs=config.training.num_train_epochs,\n","        precision= 16 if config.training.fp_16 else 32,\n","        amp_level=config.training.opt_level,\n","        gradient_clip_val=config.training.max_grad_norm,\n","    )\n","    return train_params\n","\n","# @hydra.main(config_path=\"config.yaml\")\n","def train(config: DictConfig, train_params: dict) -> None:\n","    \n","    # conduct transfer learning\n","    model = T5FineTuner(config)\n","    wandb.watch(model, log_freq=100)\n","    trainer = pl.Trainer(**train_params)\n","    trainer.fit(model)\n","\n","    model.tokenizer.save_pretrained(config.experiment.model_dir)\n","    model.model.save_pretrained(config.experiment.model_dir)\n","\n","    # trainer.test(model)\n","\n","    # torch.save(\n","    #             {\"model\": model.state_dict(), \"preds\": preds}, OUTPUT_DIR + f\"bert-base-uncased_fold{fold}_best.pth\"\n","    #         )\n","\n","# @hydra.main(config_path=\"adjacencyattentionwithoutselfloop\", config_name=\"config\")\n","def evaluation(config: DictConfig, train_params: dict) -> None:\n","    print(\"config\",config)\n","    print(\"type_config\",type(config))\n","    set_seed(42)\n","    USE_GPU = torch.cuda.is_available()\n","    config.training.n_gpu=1 if USE_GPU else 0\n","    eval_model = T5Evaluation(config, train_params)\n","    trainer = pl.Trainer(**train_params)\n","    trainer.test(eval_model)\n","  \n","def main(config: DictConfig) -> None:\n","    if os.path.exists(config.experiment.model_dir):\n","        raise \"model_dir is exist\"\n","\n","    set_seed(42)\n","    USE_GPU = torch.cuda.is_available()\n","    config.training.n_gpu=1 if USE_GPU else 0\n","    train_params = get_train_param(config)\n","\n","    Preprocess(config)\n","    train(config, train_params)\n","    evaluation(config, train_params)\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["711ae15ff82f40e0883ff00c3197c6e5","398edfab12a346259628b7e6e94608b5","1f0a21ba51af452ca84c23f9d969b6a2","b088865bb0bc4cb687ae9efca96b7d39","12c2010d488249509f12d2924ad76180","7addbe405f2644d2b601d5033681f276","d7a474333b144fab90445a1ed9567613","78ed48e18f9b4633956ebb980f8b4a07","56e2d2362cf042ae9df3c59af3b21b6b","a950d5bfa7cc408fa9e75d7a5ddca675","a8f0f87abccc4966a0278dc4100d99d2","9719c5e1676b464887154bbf0dcf6087","28f4ef79fa554a298ba74ba79597f417","f0c5e178e48f4b358414e9b3581c0205","a638138187ef47c7837807bb639ecc38","8a3442239c444bb58f96054f0682088c","39e943a38a154caa8a6038929cd6f5cd","1158150af5094e52917605d3028cf1e4","24c625354c4742609e4b4709a058efd0","a7067f7629e34e4ea5134f10b701c3c6","1797e7efe60047f3adf71b7536ea242c","f2bf94211b0c4e4bbcd4dc977f97a6b1","99e5be9462f648189e100a383203be9c","4a1ca5e0c618452fad60c0f8fc4e7829","f3488b95a1aa4d3ea712e89b93b3c42b","87019f8d0f794a4497d06c9211aff2c5","fb4d876be6b94593b7bcc3221e5347ae","d4bff213d84a42de81aa4c474ae468b5","5b9f85b7feaa4f3c81a90f32dfa9ecc5","050dcc8007664fb4a740001bc1267497","3c9334d6e7134c2a8a6409915722d721","00ed0aba038e431b8856d99dc53d2b92","8f19aba35e9740f2ad963e257605a000","890d00d7f0d64e64a7311d8479ab2e6a","b4b62762f3bb4deaa451919ce59601ca","e0ae50450a7d4a7492d357175001bf5e","bd83e1cf6d2846b6b931c3d9f0265fb4","565687a7c2174b308e68622402f354cb","b975cb927f234152830b8e6f47169409","0f6c6636f547437ea1f18bd5f8341367","713f59582e39422cb50484ccbd99e81a","f321eb16048343cd89edd73f790dfa66","9cf6b47722bd455c802680cdeef4e839","a53775c819de4b349c7922ac930f212c","8e5a2fa97ced47dca7634e574cfe6901","3054a7198483406cb10abd47be65b91a","6a33090a9bc44c379f5d1894061a4191","4679428018454b1eb4b4e1cecae74c42","5bf372526ebb4954a67fd0a3e30148c5","46bdfb6fc47b405282972650dd86df65","208b5559419b40de8276ad71192de381","8d5e9291618740c1929c203eb1d4eb45","c3855c46d7294dda8335b4f503882ea1","3e51b722d3224de58607cd818217369c","0c11fc7a1deb4bbf8be5cb960fe96166","2fb71916ecf943a3b284e2c7a8e6c73a","c74cc44ab9c446a7a2797bd4021efb60","e181b9894b424bfe955b74a90b19c309","9211c00821964d29803fcb9b7b1229bc","9d045e2eb13046a0a22e507356a1ae6b","36f3dd041fc748de87378a6567a1c793","17017989e28b442c922b719082a5401f","f0581ea1d4da491d9bda8164b3bf915e","ef552172a2a54bd2829f5b3fa2f727a4","0beb7b2d6ad34c12bacecf992e77729b","93c850d51a3d400888168ff34832f57c","f63281b1a79f4d8aaa3893ef4d58eedc","55ab68efcf164a52abfcb44cbd44c512","d9d5247995eb41a89cdddde1d21c584e","6dfe2d66383d4936987ddfc4b8e078f7","b03bbef45f3c46ce859c8e2f127fa589","a05a20c996794d74a1857c41080a2e34","c479cb8affd441cc89b8a7daec159692","19ff72e88ba64f29aea16ab4cd1fcb0c","6c20c246502444c2bfffbba4987f4afd","bc05816ea91f49a380398c1a9e033d3d","4826a195aedc42528c6f47fcd7abed2b","204f7bd706f5481f95cc0504eef5bdeb","5aeea703d4a145ba8585a57b822c8636","cbd0582213574704880f48d36e1d3e64","3d9d16c145304c0ab4830e61cce2ead7","ac666bc61f4d4056bd293a43a9cda1e9","fd421455422742b3a69654c27a9a6d4a","d0759f0eb9c34631a53bf8432e24364d","c737227a0e3e4c22ac79d1d16db96be4","f9b0f4f4297d45efa2f21f9632afbbd2","33a08564ee0d4fbc8164fe2cb0296f0d","b1296e0834c440898fdac5319f251161","294c8a51559246059ea5853189aa7ab1","0c9ffccae9e34a5a84da0c73f4882784","5bcec0373de84e7a84d3219504a0d720","c8435f25b9ca45c8a919bcb137b69381","bb80ead12dd445c4a0728c4a4107b39f","7cb5babce74e44bd86a2736c41803f8b","692a73a7ee4d454f835ba63da3cf458f","07a9e75c28a046a6a3786d0144f0317a","4389d650d04e4621b7c6136658b061c3","60d0ab4ff5a54ee8890a625c1aba04ce","186c435724da413b88e9ae0e149f1a22","c828038862b94f08a014294cdc3ac1eb","a0262dde020843b2a78fe1d8f97c6b48","c15b1d0c17b04aca9cee10fedd99de87","879fe8f3970c4219a2f6518449dc4f20","3699f74b78d5427785b07b0f3e2ae4c5","a1ed9934500940e2a927673986a3d18b","e7b07083926b41cd8ac0402fe8ad994b","956a52ee08414e5390ff06995ab876e1","e84d7339b2e24472bd28b95fed5bddc6","0ffaaeae6ae044e9ad248ebc402c0abf","fe53c64476304cac8a949bfee45db7ad","5b25139f24894f17941260b14101865f","418544e373a84b3dae7942ff565ac44d","842bfcc94be649f1ba5aaf16cc898e9c","188fcbd8782f42e38e69e0bf22a5cb96","5a967d3eaa04445f943e4ae76eb42872","7a1301d02f5b42f891a09d46a35b64c0","443f2b017b164dd09523d413dd22bd9c","8558af0be0de45bdb156fcfc15d87680","60ad44d606b1440daafad542b0f939d8","bd7ae154ec64407f924c83d95baf8408","225ae42308fe458a98b4855255cc8dca","416a45fd91e9496dab72d645577ddf77","0e66d9e774b44464bf8b93ddc26c72fb","04c5b3d38bdf4741baf9d744376c6244","46bafa1b3d764b13b31dae61ba148d59","6ff7ad282e184091be35b7c7af417c09","82a9c5b1990a4ef0ab95f9b846d82968","67674d84431e47e2a84a2762809cf6de","523c5dacbbfd4a75a6ecfc1cd1bc4dce","8400810ed09d43dfb2830f252d0d448a","22bfa5ee19c8461f8199bb1eba6ab357","2f8264247bab47f497a860859b2a455e","9a2b0f6042da4862b1d1bc00c8d853ac","a0516e37547b4ac4a106fb6730026515","926e6b70d9074273b84ac596d2f2d856","b7854ec8f269451ebeb52be0b1816c22","bcf7a8f8462f4074952799f4f0411bc8","cf8e6048cb4a48f1af3c1d896027a594","ee006b4437c54ce7bee60db01ff6fc25","68e99d24abf3448596eb96ca6c33ba30","03b1191715264ff3aa43bdcdb52ce358","03f0380aac924ff393a654c674938598","c2c1736a3bdc46c7a28e17eec53fd2c1","cf60dc5dab254254a03041f2a80c094f","bc7db7d715074663a1c28195f289e41f","1565ce76a76149bdb112154d1c633c86","bc4413f5564641479139732dfe1dbc26","c5323b63d2694d03bd3f407d6ea15f4d","ef894d4a3a1a4db19f367951d5514c1d","6dd9db4837a549cab869280a3636cc2b","5ff2195c8941402b9e15055997d3d153","74b77c3d43034d8b8a7c32a3d026a594","ea7c86272d2e4f348cd0660d506170af","606532cb09ed413e83db4a175ce42e47","442c0aa2dccb4992bcdc55cdc9b29ba2","9c739c85abb3405691cf7a4b1ade181e","80f83666457948d7be9e25268142e42f","40ab86fcce094fbfa227986b444d4112","abee7d057cb6439e9e9ab1b0c82015a0","2d20ed3508aa4aa2865b8408f52893aa","0d8373886d3d444d94c9d1e513f4d420","2a9a8e9d3df441128c9e4ad336917c95","a8714bf8b00347de8f97f7e88a94bfab","7d883a2bb72342cba7209a6abd6f24bd","dd5e96c49b0142c29f9fb8f1152d4ed3","0fb21449189e4c61975e1d9d290d6cef","59355890bb6f4d07bf0c3d5569d1ee41","85d7f0afd0d74979a03a45e1f796444a","174651e442f3426ab6ee81ce7696014f","c361f7c54abc4b64b52d4ec48bf7180d","8a03abc32939432295f3565297ae0077","7c9448a5901b44938a2e23795d9f0979","478a5f483add4f96ad39dca0613b9b02"]},"id":"Y8rY2-GGOKg-","executionInfo":{"status":"ok","timestamp":1630854650457,"user_tz":-540,"elapsed":4578827,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}},"outputId":"28c44840-7a71-4b6b-e768-93d846fda33c"},"source":["config = omegaconf.OmegaConf.load(\"config/config_pq_t5small.yaml\")\n","main(config)\n","wandb.finish()"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmacho000\u001b[0m (use `wandb login --relogin` to force relogin)\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.7<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">exp_1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/macho000/mhqg-pq_t5-small\" target=\"_blank\">https://wandb.ai/macho000/mhqg-pq_t5-small</a><br/>\n","                Run page: <a href=\"https://wandb.ai/macho000/mhqg-pq_t5-small/runs/3ansoso0\" target=\"_blank\">https://wandb.ai/macho000/mhqg-pq_t5-small/runs/3ansoso0</a><br/>\n","                Run data is saved locally in <code>wandb/run-20210905_135431-3ansoso0</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"711ae15ff82f40e0883ff00c3197c6e5","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9719c5e1676b464887154bbf0dcf6087","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/242M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99e5be9462f648189e100a383203be9c","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"890d00d7f0d64e64a7311d8479ab2e6a","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: None, using: 0 TPU cores\n","\n","  | Name  | Type                       | Params\n","-----------------------------------------------------\n","0 | model | T5ForConditionalGeneration | 60.5 M\n","-----------------------------------------------------\n","60.5 M    Trainable params\n","0         Non-trainable params\n","60.5 M    Total params\n","242.026   Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e5a2fa97ced47dca7634e574cfe6901","version_minor":0,"version_major":2},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2fb71916ecf943a3b284e2c7a8e6c73a","version_minor":0,"version_major":2},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f63281b1a79f4d8aaa3893ef4d58eedc","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n","  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"204f7bd706f5481f95cc0504eef5bdeb","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"294c8a51559246059ea5853189aa7ab1","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c828038862b94f08a014294cdc3ac1eb","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b25139f24894f17941260b14101865f","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"416a45fd91e9496dab72d645577ddf77","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a2b0f6042da4862b1d1bc00c8d853ac","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf60dc5dab254254a03041f2a80c094f","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 0 file into the W&B run directory, call wandb.save again to sync new files.\n"]},{"output_type":"stream","name":"stdout","text":["config {'experiment': {'seed': 42, 'data': 'mhqg-pq', 'data_dir': 'data/mhqg-pq/', 'model_name_or_path': 't5-small', 'tokenizer_name_or_path': 't5-small', 'model_dir': 'content/mhqg-pq_t5-small_20210905_2246', 'wandb': {'exp_num': 1, 'project': 'mhqg-pq_t5-small', 'checkpoint_path': 'checkpoint/'}}, 'model': {'max_input_length': 512, 'max_target_length': 100}, 'training': {'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'gradient_accumulation_steps': 1, 'early_stop_callback': True, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42, 'train_batch_size': 2, 'eval_batch_size': 2, 'test_batch_size': 8, 'num_train_epochs': 8, 'precision': 16, 'n_gpu': 1}}\n","type_config <class 'omegaconf.dictconfig.DictConfig'>\n"]},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: None, using: 0 TPU cores\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"442c0aa2dccb4992bcdc55cdc9b29ba2","version_minor":0,"version_major":2},"text/plain":["Testing: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","DATALOADER:0 TEST RESULTS\n","{}\n","--------------------------------------------------------------------------------\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 475<br/>Program ended successfully."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fb21449189e4c61975e1d9d290d6cef","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.02MB of 0.02MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Find user logs for this run at: <code>wandb/run-20210905_135431-3ansoso0/logs/debug.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Find internal logs for this run at: <code>wandb/run-20210905_135431-3ansoso0/logs/debug-internal.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<h3>Run summary:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>train/loss_step</td><td>0.08151</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>_step</td><td>39167</td></tr><tr><td>_runtime</td><td>4565</td></tr><tr><td>_timestamp</td><td>1630854636</td></tr><tr><td>train/loss_epoch</td><td>0.24363</td></tr><tr><td>valid/loss_epoch</td><td>0.2696</td></tr><tr><td>Bleu_1</td><td>0.76929</td></tr><tr><td>Bleu_2</td><td>0.67672</td></tr><tr><td>Bleu_3</td><td>0.60752</td></tr><tr><td>Bleu_4</td><td>0.53684</td></tr><tr><td>METEOR</td><td>0.41192</td></tr><tr><td>ROUGE_L</td><td>0.73659</td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<h3>Run history:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>train/loss_step</td><td>▅▆█▂▃▃▃▃▂▅▂▁▂▂▂▂▂▃▂▁▂▂▁▂▂▁▂▂▁▂▁▂▁▂▂▂▁▂▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/loss_epoch</td><td>█▃▂▂▂▁▁▁</td></tr><tr><td>valid/loss_epoch</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>Bleu_1</td><td>▁</td></tr><tr><td>Bleu_2</td><td>▁</td></tr><tr><td>Bleu_3</td><td>▁</td></tr><tr><td>Bleu_4</td><td>▁</td></tr><tr><td>METEOR</td><td>▁</td></tr><tr><td>ROUGE_L</td><td>▁</td></tr></table><br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","                    <br/>Synced <strong style=\"color:#cdcd00\">exp_1</strong>: <a href=\"https://wandb.ai/macho000/mhqg-pq_t5-small/runs/3ansoso0\" target=\"_blank\">https://wandb.ai/macho000/mhqg-pq_t5-small/runs/3ansoso0</a><br/>\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ztO5Gqs2OKg_","executionInfo":{"status":"ok","timestamp":1630854664817,"user_tz":-540,"elapsed":275,"user":{"displayName":"Kosuke Aigo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8bGNs_XsxiFA4-kq5-koM9uVsQo4bz2KIDtRQrw=s64","userId":"01303562836135023230"}},"outputId":"05aaa594-91f9-416a-992b-3162a0699f28"},"source":["!nvidia-smi"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep  5 15:11:04 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P0    35W / 250W |   2063MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"k8noV15Rg070"},"source":[""],"execution_count":null,"outputs":[]}]}